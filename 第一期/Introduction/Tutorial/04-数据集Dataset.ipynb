{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集 Dataset\n",
    "\n",
    "数据是深度学习的基础，高质量的数据输入将在整个深度神经网络中起到积极作用。MindSpore提供基于Pipeline的[数据引擎](https://www.mindspore.cn/docs/zh-CN/r2.3/design/data_engine.html)，通过[数据集（Dataset）](https://www.mindspore.cn/tutorials/zh-CN/r2.3/beginner/dataset.html)和[数据变换（Transforms）](https://www.mindspore.cn/tutorials/zh-CN/r2.3/beginner/transforms.html)实现高效的数据预处理。其中Dataset是Pipeline的起始，用于加载原始数据。`mindspore.dataset`提供了内置的文本、图像、音频等数据集加载接口，并提供了自定义数据集加载接口。\n",
    "\n",
    "此外MindSpore的领域开发库也提供了大量的预加载数据集，可以使用API一键下载使用。本教程将分别对不同的数据集加载方式、数据集常见操作和自定义数据集方法进行详细阐述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.2.14，如需更换mindspore版本，可更改下面mindspore的版本号\n",
    "!pip uninstall mindspore -y\n",
    "!pip install -i https://pypi.mirrors.ustc.edu.cn/simple mindspore==2.2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore.dataset import vision\n",
    "from mindspore.dataset import MnistDataset, GeneratorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "我们使用**Mnist**数据集作为样例，介绍使用`mindspore.dataset`进行加载的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mindspore.dataset`提供的接口**仅支持解压后的数据文件**，因此我们使用`download`库下载数据集并解压。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from open datasets\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "压缩文件删除后，直接加载，可以看到其数据类型为MnistDataset。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(\"MNIST_Data/train\", shuffle=False)\n",
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集迭代\n",
    "\n",
    "数据集加载后，一般以迭代方式获取数据，然后送入神经网络中进行训练。我们可以用[create_tuple_iterator](https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_tuple_iterator.html)或[create_dict_iterator](https://www.mindspore.cn/docs/zh-CN/r2.3/api_python/dataset/dataset_method/iterator/mindspore.dataset.Dataset.create_dict_iterator.html)接口创建数据迭代器，迭代访问数据。\n",
    "\n",
    "访问的数据类型默认为`Tensor`；若设置`output_numpy=True`，访问的数据类型为`Numpy`。\n",
    "\n",
    "下面定义一个可视化函数，迭代9张图片进行展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(dataset):\n",
    "    figure = plt.figure(figsize=(4, 4))\n",
    "    cols, rows = 3, 3\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "    for idx, (image, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        figure.add_subplot(rows, cols, idx + 1)\n",
    "        plt.title(int(label))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image.asnumpy().squeeze(), cmap=\"gray\")\n",
    "        if idx == cols * rows - 1:\n",
    "            break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集常用操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline的设计理念使得数据集的常用操作采用`dataset = dataset.operation()`的异步执行方式，执行操作返回新的Dataset，此时不执行具体操作，而是在Pipeline中加入节点，最终进行迭代时，并行执行整个Pipeline。\n",
    "\n",
    "下面分别介绍几种常见的数据集操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle\n",
    "\n",
    "数据集随机`shuffle`可以消除数据排列造成的分布不均问题。\n",
    "\n",
    "![op-shuffle](pic/op_shuffle.png)\n",
    "\n",
    "`mindspore.dataset`提供的数据集在加载时可配置`shuffle=True`，或使用如下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(buffer_size=64)\n",
    "\n",
    "visualize(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map`操作是数据预处理的关键操作，可以针对数据集指定列（column）添加数据变换（Transforms），将数据变换应用于该列数据的每个元素，并返回包含变换后元素的新数据集。\n",
    "\n",
    "> Dataset支持的不同变换类型详见[数据变换Transforms](https://www.mindspore.cn/tutorials/zh-CN/r2.3/beginner/transforms.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape, image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们对Mnist数据集做数据缩放处理，将图像统一除以255，数据类型由uint8转为了float32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(vision.Rescale(1.0 / 255.0, 0), input_columns='image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比map前后的数据，可以看到数据类型变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape, image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch\n",
    "\n",
    "将数据集打包为固定大小的`batch`是在有限硬件资源下使用梯度下降进行模型优化的折中方法，可以保证梯度下降的随机性和优化计算量。\n",
    "\n",
    "![op-batch](pic/op_batch.png)\n",
    "\n",
    "一般我们会设置一个固定的batch size，将连续的数据分为若干批（batch）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch后的数据增加一维，大小为`batch_size`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(train_dataset.create_tuple_iterator())\n",
    "print(image.shape, image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mindspore.dataset`模块提供了一些常用的公开数据集和标准格式数据集的加载API。\n",
    "\n",
    "对于MindSpore暂不支持直接加载的数据集，可以构造自定义数据加载类或自定义数据集生成函数的方式来生成数据集，然后通过`GeneratorDataset`接口实现自定义方式的数据集加载。\n",
    "\n",
    "`GeneratorDataset`支持通过可随机访问数据集对象、可迭代数据集对象和生成器(generator)构造自定义数据集，下面分别对其进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可随机访问数据集\n",
    "\n",
    "可随机访问数据集是实现了`__getitem__`和`__len__`方法的数据集，表示可以通过索引/键直接访问对应位置的数据样本。\n",
    "\n",
    "例如，当使用`dataset[idx]`访问这样的数据集时，可以读取dataset内容中第idx个样本或标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random-accessible object as input source\n",
    "class RandomAccessDataset:\n",
    "    def __init__(self):\n",
    "        self._data = np.ones((5, 2))\n",
    "        self._label = np.zeros((5, 1))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._data[index], self._label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = RandomAccessDataset()\n",
    "dataset = GeneratorDataset(source=loader, column_names=[\"data\", \"label\"])\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list, tuple are also supported.\n",
    "loader = [np.array(0), np.array(1), np.array(2)]\n",
    "dataset = GeneratorDataset(source=loader, column_names=[\"data\"])\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可迭代数据集\n",
    "\n",
    "可迭代的数据集是实现了`__iter__`和`__next__`方法的数据集，表示可以通过迭代的方式逐步获取数据样本。这种类型的数据集特别适用于随机访问成本太高或者不可行的情况。\n",
    "\n",
    "例如，当使用`iter(dataset)`的形式访问数据集时，可以读取从数据库、远程服务器返回的数据流。\n",
    "\n",
    "下面构造一个简单迭代器，并将其加载至`GeneratorDataset`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator as input source\n",
    "class IterableDataset():\n",
    "    def __init__(self, start, end):\n",
    "        '''init the class object to hold the data'''\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    def __next__(self):\n",
    "        '''iter one data and return'''\n",
    "        return next(self.data)\n",
    "    def __iter__(self):\n",
    "        '''reset the iter'''\n",
    "        self.data = iter(range(self.start, self.end))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = IterableDataset(1, 5)\n",
    "dataset = GeneratorDataset(source=loader, column_names=[\"data\"])\n",
    "\n",
    "for d in dataset:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器\n",
    "\n",
    "生成器也属于可迭代的数据集类型，其直接依赖Python的生成器类型`generator`返回数据，直至生成器抛出`StopIteration`异常。\n",
    "\n",
    "下面构造一个生成器，并将其加载至`GeneratorDataset`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def my_generator(start, end):\n",
    "    for i in range(start, end):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since a generator instance can be only iterated once, we need to wrap it by lambda to generate multiple instances\n",
    "dataset = GeneratorDataset(source=lambda: my_generator(3, 6), column_names=[\"data\"])\n",
    "\n",
    "for d in dataset:\n",
    "    print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda-python3",
   "language": "python",
   "name": "conda-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c9da313289c39257cb28b126d2dadd33153d4da4d524f730c81a4aaccbd2ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
