{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fab270e-643c-4c82-a662-8a4d01f11a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://192.168.0.94:8888/repository/pypi/simple\n",
      "Collecting mindnlp\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/mindnlp/0.3.1/mindnlp-0.3.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/evaluate/0.4.1/evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/tokenizers/0.20.0/tokenizers-0.20.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/ml-dtypes/0.2.0/ml_dtypes-0.2.0.tar.gz (698 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting safetensors\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/safetensors/0.4.5/safetensors-0.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.3/436.3 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/datasets/2.13.2/datasets-2.13.2-py3-none-any.whl (512 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindnlp) (2.27.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/sentencepiece/0.2.0/sentencepiece-0.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting pytest==7.2.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/pytest/7.2.0/pytest-7.2.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindnlp) (4.64.1)\n",
      "Collecting addict\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/addict/2.4.0/addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting pyctcdecode\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/pyctcdecode/0.5.0/pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting regex\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/regex/2024.4.16/regex-2024.4.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (761 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mindspore in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindnlp) (1.7.0)\n",
      "Collecting jieba\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/jieba/0.42.1/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (22.1.0)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (21.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (4.12.0)\n",
      "Collecting exceptiongroup>=1.0.0rc8\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/exceptiongroup/1.2.2/exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: iniconfig in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pytest==7.2.0->mindnlp) (1.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from datasets->mindnlp) (5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from datasets->mindnlp) (1.19.5)\n",
      "Collecting aiohttp\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/aiohttp/3.8.6/aiohttp-3.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (987 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.0/988.0 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/fsspec/2023.1.0/fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from datasets->mindnlp) (1.1.5)\n",
      "Collecting multiprocess\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/multiprocess/0.70.15/multiprocess-0.70.15-py37-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/huggingface-hub/0.16.4/huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=8.0.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/pyarrow/12.0.1/pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.1/39.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/xxhash/3.5.0/xxhash-3.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.7/194.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/dill/0.3.6/dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from requests->mindnlp) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from requests->mindnlp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from requests->mindnlp) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from requests->mindnlp) (1.26.12)\n",
      "Collecting responses<0.19\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/responses/0.18.0/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: asttokens>=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindspore->mindnlp) (2.0.8)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindspore->mindnlp) (3.20.1)\n",
      "Requirement already satisfied: scipy>=1.5.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindspore->mindnlp) (1.5.2)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindspore->mindnlp) (5.8.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from mindspore->mindnlp) (9.2.0)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached http://192.168.0.94:8888/repository/pypi/packages/numpy/1.21.6/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting pygtrie<3.0,>=2.1\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/pygtrie/2.5.0/pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Collecting hypothesis<7,>=6.14\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/hypothesis/6.79.4/hypothesis-6.79.4-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.7/417.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from asttokens>=2.0.0->mindspore->mindnlp) (1.16.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/yarl/1.9.4/yarl-1.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/multidict/6.0.5/multidict-6.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/aiosignal/1.3.1/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/frozenlist/1.3.3/frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/asynctest/0.13.0/asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/async-timeout/4.0.3/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from aiohttp->datasets->mindnlp) (3.10.0.0)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->mindnlp) (3.0.12)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from hypothesis<7,>=6.14->pyctcdecode->mindnlp) (2.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest==7.2.0->mindnlp) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from packaging->pytest==7.2.0->mindnlp) (3.0.9)\n",
      "Collecting multiprocess\n",
      "  Downloading http://192.168.0.94:8888/repository/pypi/packages/multiprocess/0.70.14/multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pandas->datasets->mindnlp) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages (from pandas->datasets->mindnlp) (2.8.2)\n",
      "Building wheels for collected packages: jieba, ml-dtypes\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=27014ae891cf088fcca4e214d5a21e4decfaa27f5dba3cf3a253aa1249d72cc6\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/b5/f3/10/9efe674d4a0bc230e1f948bfd90f3133a2bfec55db81b87bce\n",
      "  Building wheel for ml-dtypes (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-dtypes: filename=ml_dtypes-0.2.0-cp37-cp37m-linux_x86_64.whl size=979909 sha256=4bdbe95ade06c81e5f6c9315d02ce66478748207254d5888419a7e8672e9a4b9\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/93/3f/44/9a573bb1b9665f5f1f1e77db373554c02f51d1928788c3ada6\n",
      "Successfully built jieba ml-dtypes\n",
      "Installing collected packages: sentencepiece, pygtrie, jieba, addict, xxhash, safetensors, regex, numpy, multidict, fsspec, frozenlist, exceptiongroup, dill, asynctest, async-timeout, yarl, responses, pyarrow, multiprocess, ml-dtypes, hypothesis, huggingface-hub, aiosignal, tokenizers, pytest, pyctcdecode, aiohttp, datasets, evaluate, mindnlp\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 7.1.3\n",
      "    Uninstalling pytest-7.1.3:\n",
      "      Successfully uninstalled pytest-7.1.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mindvision 0.1.0 requires scikit-learn>=0.23.1, but you have scikit-learn 0.22.1 which is incompatible.\n",
      "mindquantum 0.6.0 requires scipy>=1.5.3, but you have scipy 1.5.2 which is incompatible.\n",
      "mindinsight 1.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\n",
      "mindinsight 1.7.0 requires scikit-learn>=0.23.1, but you have scikit-learn 0.22.1 which is incompatible.\n",
      "modelarts 1.4.25 requires attrs>=22.2.0, but you have attrs 22.1.0 which is incompatible.\n",
      "modelarts 1.4.25 requires huaweicloudsdkcore<=3.1.58, but you have huaweicloudsdkcore 3.1.113 which is incompatible.\n",
      "modelarts 1.4.25 requires lxml==5.1.0, but you have lxml 4.9.1 which is incompatible.\n",
      "modelarts 1.4.25 requires matplotlib==3.5.2, but you have matplotlib 3.5.1 which is incompatible.\n",
      "modelarts 1.4.25 requires psutil==5.9.5, but you have psutil 5.8.0 which is incompatible.\n",
      "modelarts 1.4.25 requires requests>=2.31.0, but you have requests 2.27.1 which is incompatible.\n",
      "modelarts 1.4.25 requires tenacity<=8.2.2, but you have tenacity 8.2.3 which is incompatible.\n",
      "modelarts 1.4.25 requires typing-extensions==4.7.1, but you have typing-extensions 3.10.0.0 which is incompatible.\n",
      "modelarts 1.4.25 requires urllib3==1.26.18, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed addict-2.4.0 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 asynctest-0.13.0 datasets-2.13.2 dill-0.3.6 evaluate-0.4.1 exceptiongroup-1.2.2 frozenlist-1.3.3 fsspec-2023.1.0 huggingface-hub-0.16.4 hypothesis-6.79.4 jieba-0.42.1 mindnlp-0.3.1 ml-dtypes-0.2.0 multidict-6.0.5 multiprocess-0.70.14 numpy-1.21.6 pyarrow-12.0.1 pyctcdecode-0.5.0 pygtrie-2.5.0 pytest-7.2.0 regex-2024.4.16 responses-0.18.0 safetensors-0.4.5 sentencepiece-0.2.0 tokenizers-0.20.0 xxhash-3.5.0 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 安装mindnlp\n",
    "!pip install mindnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90957e-c68a-4a9c-ad47-bf2768807dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mindspore\n",
    "from mindspore.dataset import text, GeneratorDataset, transforms\n",
    "from mindspore import nn, context\n",
    "\n",
    "from mindnlp._legacy.engine import Trainer, Evaluator\n",
    "from mindnlp._legacy.engine.callbacks import CheckpointCallback, BestModelCallback\n",
    "from mindnlp._legacy.metrics import Accuracy\n",
    "\n",
    "# prepare dataset\n",
    "class SentimentDataset:\n",
    "    \"\"\"Sentiment Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self._labels, self._text_a = [], []\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        with open(self.path, \"r\", encoding=\"utf-8\") as f:\n",
    "            dataset = f.read()\n",
    "        lines = dataset.split(\"\\n\")\n",
    "        for line in lines[1:-1]:\n",
    "            label, text_a = line.split(\"\\t\")\n",
    "            self._labels.append(int(label))\n",
    "            self._text_a.append(text_a)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._labels[index], self._text_a[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e6def-a76a-485a-978f-004dd3ff5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载数据集\n",
    "!wget https://baidu-nlp.bj.bcebos.com/emotion_detection-dataset-1.0.0.tar.gz -O emotion_detection.tar.gz\n",
    "tar xvf emotion_detection.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390663d6-fb60-4018-9f62-83f157f895b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载和数据预处理\n",
    "import numpy as np\n",
    "\n",
    "def process_dataset(source, tokenizer, max_seq_len=64, batch_size=32, shuffle=True):\n",
    "    is_ascend = mindspore.get_context('device_target') == 'Ascend'\n",
    "\n",
    "    column_names = [\"label\", \"text_a\"]\n",
    "\n",
    "    dataset = GeneratorDataset(source, column_names=column_names, shuffle=shuffle)\n",
    "    # transforms\n",
    "    type_cast_op = transforms.TypeCast(mindspore.int32)\n",
    "    def tokenize_and_pad(text):\n",
    "        if is_ascend:\n",
    "            tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=max_seq_len)\n",
    "        else:\n",
    "            tokenized = tokenizer(text)\n",
    "        return tokenized['input_ids'], tokenized['attention_mask']\n",
    "    # map dataset\n",
    "    dataset = dataset.map(operations=tokenize_and_pad, input_columns=\"text_a\", output_columns=['input_ids', 'attention_mask'])\n",
    "    dataset = dataset.map(operations=[type_cast_op], input_columns=\"label\", output_columns='labels')\n",
    "    # batch dataset\n",
    "    if is_ascend:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    else:\n",
    "        dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                         'attention_mask': (None, 0)})\n",
    "\n",
    "    return dataset\n",
    "\n",
    "from mindnlp.transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "tokenizer.pad_token_id\n",
    "\n",
    "dataset_train = process_dataset(SentimentDataset(\"data/train.tsv\"), tokenizer)\n",
    "dataset_val = process_dataset(SentimentDataset(\"data/dev.tsv\"), tokenizer)\n",
    "dataset_test = process_dataset(SentimentDataset(\"data/test.tsv\"), tokenizer, shuffle=False)\n",
    "\n",
    "print(next(dataset_train.create_tuple_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb97e5b-b9ee-4654-9cc8-07bbdcdc2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型构建\n",
    "from mindnlp.transformers import BertForSequenceClassification, BertModel\n",
    "from mindnlp._legacy.amp import auto_mixed_precision\n",
    "\n",
    "# set bert config and define parameters for training\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=3)\n",
    "model = auto_mixed_precision(model, 'O1')\n",
    "\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=2e-5)\n",
    "\n",
    "metric = Accuracy()\n",
    "# define callbacks to save checkpoints\n",
    "ckpoint_cb = CheckpointCallback(save_path='checkpoint', ckpt_name='bert_emotect', epochs=1, keep_checkpoint_max=2)\n",
    "best_model_cb = BestModelCallback(save_path='checkpoint', ckpt_name='bert_emotect_best', auto_load=True)\n",
    "\n",
    "trainer = Trainer(network=model, train_dataset=dataset_train,\n",
    "                  eval_dataset=dataset_val, metrics=metric,\n",
    "                  epochs=5, optimizer=optimizer, callbacks=[ckpoint_cb, best_model_cb])\n",
    "# start training\n",
    "trainer.run(tgt_columns=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0959406-78c9-43c3-a844-21e52bb39e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型验证\n",
    "evaluator = Evaluator(network=model, eval_dataset=dataset_test, metrics=metric)\n",
    "evaluator.run(tgt_columns=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615caaf5-81b2-46b1-a1d8-1a0695e49d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型推理\n",
    "dataset_infer = SentimentDataset(\"data/infer.tsv\")\n",
    "\n",
    "def predict(text, label=None):\n",
    "    label_map = {0: \"消极\", 1: \"中性\", 2: \"积极\"}\n",
    "\n",
    "    text_tokenized = Tensor([tokenizer(text).input_ids])\n",
    "    logits = model(text_tokenized)\n",
    "    predict_label = logits[0].asnumpy().argmax()\n",
    "    info = f\"inputs: '{text}', predict: '{label_map[predict_label]}'\"\n",
    "    if label is not None:\n",
    "        info += f\" , label: '{label_map[label]}'\"\n",
    "    print(info)\n",
    "\n",
    "from mindspore import Tensor\n",
    "\n",
    "for label, text in dataset_infer:\n",
    "    predict(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb6a5a-178b-426b-b137-446ae743ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义推理数据集\n",
    "predict(\"家人们咱就是说一整个无语住了 绝绝子叠buff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
