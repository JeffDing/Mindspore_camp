{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN图像风格迁移互换\n",
    "\n",
    "> 本案例运行需要较大内存，建议在Ascend/GPU上运行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型介绍\n",
    "\n",
    "### 模型简介\n",
    "\n",
    "CycleGAN(Cycle Generative Adversarial Network) 即循环对抗生成网络，来自论文 [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593) 。该模型实现了一种在没有配对示例的情况下学习将图像从源域 X 转换到目标域 Y 的方法。\n",
    "\n",
    "该模型一个重要应用领域是域迁移(Domain Adaptation)，可以通俗地理解为图像风格迁移。其实在 CycleGAN 之前，就已经有了域迁移模型，比如 Pix2Pix ，但是 Pix2Pix 要求训练数据必须是成对的，而现实生活中，要找到两个域（画风）中成对出现的图片是相当困难的，因此 CycleGAN 诞生了，它只需要两种域的数据，而不需要他们有严格对应关系，是一种新的无监督的图像迁移网络。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 模型结构\n",
    "\n",
    "CycleGAN 网络本质上是由两个镜像对称的 GAN 网络组成，其结构如下图所示（图片来源于原论文）：\n",
    "\n",
    "![CycleGAN](./images/CycleGAN.png)\n",
    "\n",
    "\n",
    "该模型一个很重要的部分就是损失函数，在所有损失里面循环一致损失(Cycle Consistency Loss)是最重要的。循环损失的计算过程如下图所示（图片来源于原论文）：\n",
    "\n",
    "![Cycle Consistency Loss](./images/CycleGAN_1.png)\n",
    "\n",
    "循环损失捕捉了这样的直觉，即如果我们从一个域转换到另一个域，然后再转换回来，我们应该到达我们开始的地方。详细的训练过程见下文代码。\n",
    "\n",
    "本任务旨在实现破损草图到目标线稿图之间的转化。\n",
    "\n",
    "![sketch_lineart](./images/sketch_lineart.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "本案例使用的数据集里面的图片为经图线稿图数据。图像被统一缩放为256×256像素大小，其中用于训练的线稿图片25654张、草图图片25654张，用于测试的线稿图片100张、草图图片116张。\n",
    "\n",
    "这里对数据进行了随机裁剪、水平随机翻转和归一化的预处理.\n",
    "\n",
    "### 数据集下载\n",
    "\n",
    "使用 `download` 接口下载数据集，并将下载后的数据集自动解压到当前目录下。数据下载之前需要使用 `pip install download` 安装 `download` 包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.3.0，如需更换mindspore版本，可更改下面 MINDSPORE_VERSION 变量\n",
    "!pip uninstall mindspore -y\n",
    "%env MINDSPORE_VERSION=2.3.0\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/${MINDSPORE_VERSION}/MindSpore/unified/aarch64/mindspore-${MINDSPORE_VERSION}-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.mirrors.ustc.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看当前 mindspore 版本\n",
    "!pip show mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore\n",
    "\n",
    "#设置使用的设备\n",
    "mindspore.set_context(device_target='Ascend')##gpu,cpu,Ascend\n",
    "print(mindspore.get_context(attr_key='device_target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载数据集\n",
    "from download import download\n",
    "\n",
    "url = \"https://6169fb4615b14dbcb6b2cb1c4eb78bb2.obs.cn-north-4.myhuaweicloud.com/Cyc_line.zip\"\n",
    "\n",
    "download(url, \"./localdata\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#下载预训练模型参数\n",
    "from download import download\n",
    "\n",
    "url = \"https://6169fb4615b14dbcb6b2cb1c4eb78bb2.obs.cn-north-4.myhuaweicloud.com/checkpoints.zip\"\n",
    "\n",
    "download(url, \"./ckpt\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import mindspore.dataset as de\n",
    "import mindspore.dataset.vision as C\n",
    "\n",
    "\"\"\"数据集分布式采样器\"\"\"\n",
    "class DistributedSampler:\n",
    "    \"\"\"Distributed sampler.\"\"\"\n",
    "    def __init__(self, dataset_size, num_replicas=None, rank=None, shuffle=True):\n",
    "        if num_replicas is None:\n",
    "            print(\"***********Setting world_size to 1 since it is not passed in ******************\")\n",
    "            num_replicas = 1\n",
    "        if rank is None:\n",
    "            print(\"***********Setting rank to 0 since it is not passed in ******************\")\n",
    "            rank = 0\n",
    "        self.dataset_size = dataset_size\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(math.ceil(dataset_size * 1.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # deterministically shuffle based on epoch\n",
    "        if self.shuffle:\n",
    "            indices = np.random.RandomState(seed=self.epoch).permutation(self.dataset_size)\n",
    "            # np.array type. number from 0 to len(dataset_size)-1, used as index of dataset\n",
    "            indices = indices.tolist()\n",
    "            self.epoch += 1\n",
    "            # change to list type\n",
    "        else:\n",
    "            indices = list(range(self.dataset_size))\n",
    "\n",
    "        # add extra samples to make it evenly divisible\n",
    "        indices += indices[:(self.total_size - len(indices))]\n",
    "        assert len(indices) == self.total_size\n",
    "\n",
    "        # subsample\n",
    "        indices = indices[self.rank:self.total_size:self.num_replicas]\n",
    "        assert len(indices) == self.num_samples\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"加载Cycle GAN 数据集.\"\"\"\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.tif', '.tiff']\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Judge whether it is a picture.\"\"\"\n",
    "    return any(filename.lower().endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir_path, max_dataset_size=float(\"inf\")):\n",
    "    \"\"\"Return image list in dir.\"\"\"\n",
    "    images = []\n",
    "    assert os.path.isdir(dir_path), '%s is not a valid directory' % dir_path\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir_path)):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images[:min(max_dataset_size, len(images))]\n",
    "\n",
    "class UnalignedDataset:\n",
    "    \"\"\"\n",
    "    This dataset class can load unaligned/unpaired datasets.\n",
    "    It requires two directories to host training images from domain A '/path/to/data/trainA'\n",
    "    and from domain B '/path/to/data/trainB' respectively.\n",
    "    You can train the model with the dataset flag '--dataroot /path/to/data'.\n",
    "    Similarly, you need to prepare two directories:\n",
    "    '/path/to/data/testA' and '/path/to/data/testB' during test time.\n",
    "    Returns:\n",
    "        Two domain image path list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataroot, max_dataset_size=float(\"inf\"), use_random=True):\n",
    "        self.dir_A = os.path.join(dataroot, 'trainA')\n",
    "        self.dir_B = os.path.join(dataroot, 'trainB')\n",
    "\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A, max_dataset_size))  # load images from '/path/to/data/trainA'\n",
    "        self.B_paths = sorted(make_dataset(self.dir_B, max_dataset_size))  # load images from '/path/to/data/trainB'\n",
    "        self.A_size = len(self.A_paths)  # get the size of dataset A\n",
    "        self.B_size = len(self.B_paths)  # get the size of dataset B\n",
    "        self.use_random = use_random\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data point and its metadata information.\n",
    "\n",
    "        Parameters:\n",
    "            index (int)      -- a random integer for data indexing\n",
    "\n",
    "        Returns a dictionary that contains A, B, A_paths and B_paths\n",
    "            A (tensor)       -- an image in the input domain\n",
    "            B (tensor)       -- its corresponding image in the target domain\n",
    "            A_paths (str)    -- image paths\n",
    "            B_paths (str)    -- image paths\n",
    "        \"\"\"\n",
    "        index_B = index % self.B_size\n",
    "        if index % max(self.A_size, self.B_size) == 0 and self.use_random:\n",
    "            random.shuffle(self.A_paths)\n",
    "            index_B = random.randint(0, self.B_size - 1)\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        B_path = self.B_paths[index_B]\n",
    "        A_img = np.array(Image.open(A_path).convert('RGB'))\n",
    "        B_img = np.array(Image.open(B_path).convert('RGB'))\n",
    "\n",
    "        return A_img, B_img\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        \"\"\"\n",
    "        return max(self.A_size, self.B_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataroot,batch_size=1,use_random=True,device_num=1,rank=0,max_dataset_size=float(\"inf\"),image_size=256):\n",
    "    \"\"\"\n",
    "    Create dataset\n",
    "    This dataset class can load images for train or test.\n",
    "    Args:\n",
    "        dataroot (str): Images root directory.\n",
    "    Returns:\n",
    "        RGB Image list.\n",
    "    \"\"\"\n",
    "    shuffle = use_random\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    num_parallel_workers = min(1, int(cores / device_num))\n",
    "\n",
    "    mean = [0.5 * 255] * 3\n",
    "    std = [0.5 * 255] * 3\n",
    "    \n",
    "    dataset = UnalignedDataset(dataroot, max_dataset_size=max_dataset_size, use_random=use_random)\n",
    "    distributed_sampler = DistributedSampler(len(dataset), device_num, rank, shuffle=shuffle)\n",
    "    ds = de.GeneratorDataset(dataset, column_names=[\"image_A\", \"image_B\"],\n",
    "                             sampler=distributed_sampler, num_parallel_workers=num_parallel_workers)\n",
    "    if use_random:\n",
    "        trans = [\n",
    "            C.RandomResizedCrop(image_size, scale=(0.5, 1.0), ratio=(0.75, 1.333)),\n",
    "            C.RandomHorizontalFlip(prob=0.5),\n",
    "            C.Normalize(mean=mean, std=std),\n",
    "            C.HWC2CHW()\n",
    "        ]\n",
    "    else:\n",
    "        trans = [\n",
    "            C.Resize((image_size, image_size)),\n",
    "            C.Normalize(mean=mean, std=std),\n",
    "            C.HWC2CHW()\n",
    "        ]\n",
    "    ds = ds.map(operations=trans, input_columns=[\"image_A\"], num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.map(operations=trans, input_columns=[\"image_B\"], num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#根据设备情况调整训练参数\n",
    "\n",
    "dataroot = \"./localdata\"\n",
    "batch_size = 12\n",
    "device_num = 1\n",
    "rank = 0\n",
    "use_random = True\n",
    "max_dataset_size = 24000\n",
    "image_size = 256\n",
    "\n",
    "cyclegan_ds = create_dataset(dataroot=dataroot,max_dataset_size=max_dataset_size,batch_size=batch_size,device_num=device_num,rank = rank,use_random=use_random,image_size=image_size)\n",
    "datasize = cyclegan_ds.get_dataset_size()\n",
    "print(\"Datasize: \", datasize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "\n",
    "通过 `create_dict_iterator` 函数将数据转换成字典迭代器，然后使用 `matplotlib` 模块可视化部分训练数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T03:21:30.619610Z",
     "start_time": "2023-03-07T03:21:30.302433Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"图片展示\"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5), dpi=60)\n",
    "\n",
    "for i, data in enumerate(cyclegan_ds.create_dict_iterator()):\n",
    "    if i < 5:\n",
    "        show_images_a = data[\"image_A\"]\n",
    "        show_images_b = data[\"image_B\"]\n",
    "        show_images_a = (show_images_a.asnumpy()[0]+1)/2  # 转换为NumPy数组并去除多余的维度\n",
    "        show_images_b = (show_images_b.asnumpy()[0]+1)/2 # 转换为NumPy数组并去除多余的维度\n",
    "\n",
    "        # 确保通道顺序正确（假设从RGB转换为BGR）\n",
    "        show_images_a = show_images_a.transpose((1, 2, 0))  # 将通道维度移动到最后\n",
    "        show_images_b = show_images_b.transpose((1, 2, 0))  # 将通道维度移动到最后\n",
    "        show_images_a = show_images_a[..., ::-1]  # 反转通道顺序（从RGB到BGR）\n",
    "        show_images_b = show_images_b[..., ::-1]  # 反转通道顺序（从RGB到BGR）\n",
    "\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(show_images_a)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.imshow(show_images_b)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建生成器\n",
    "\n",
    "本案例生成器的模型结构参考的 ResNet 模型的结构，参考原论文，对于128×128大小的输入图片采用6个残差块相连，图片大小为256×256以上的需要采用9个残差块相连，所以本文网络有9个残差块相连，超参数 `n_layers` 参数控制残差块数。\n",
    "\n",
    "生成器的结构如下所示：\n",
    "\n",
    "![CycleGAN Generator](./images/CycleGAN_2.jpg)\n",
    "\n",
    "具体的模型结构请参照下文代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T03:27:08.204844Z",
     "start_time": "2023-03-07T03:27:08.076183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "weight_init = Normal(sigma=0.02)\n",
    "\n",
    "class ConvNormReLU(nn.Cell):\n",
    "    def __init__(self, input_channel, out_planes, kernel_size=4, stride=2, alpha=0.2, norm_mode='instance',\n",
    "                 pad_mode='CONSTANT', use_relu=True, padding=None, transpose=False):\n",
    "        super(ConvNormReLU, self).__init__()\n",
    "        norm = nn.BatchNorm2d(out_planes)\n",
    "        if norm_mode == 'instance':\n",
    "            norm = nn.BatchNorm2d(out_planes, affine=False)\n",
    "        has_bias = (norm_mode == 'instance')\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        if pad_mode == 'CONSTANT':\n",
    "            if transpose:\n",
    "                conv = nn.Conv2dTranspose(input_channel, out_planes, kernel_size, stride, pad_mode='same',\n",
    "                                          has_bias=has_bias, weight_init=weight_init)\n",
    "            else:\n",
    "                conv = nn.Conv2d(input_channel, out_planes, kernel_size, stride, pad_mode='pad',\n",
    "                                 has_bias=has_bias, padding=padding, weight_init=weight_init)\n",
    "            layers = [conv, norm]\n",
    "        else:\n",
    "            paddings = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "            pad = nn.Pad(paddings=paddings, mode=pad_mode)\n",
    "            if transpose:\n",
    "                conv = nn.Conv2dTranspose(input_channel, out_planes, kernel_size, stride, pad_mode='pad',\n",
    "                                          has_bias=has_bias, weight_init=weight_init)\n",
    "            else:\n",
    "                conv = nn.Conv2d(input_channel, out_planes, kernel_size, stride, pad_mode='pad',\n",
    "                                 has_bias=has_bias, weight_init=weight_init)\n",
    "            layers = [pad, conv, norm]\n",
    "        if use_relu:\n",
    "            relu = nn.ReLU()\n",
    "            if alpha > 0:\n",
    "                relu = nn.LeakyReLU(alpha)\n",
    "            layers.append(relu)\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    def __init__(self, dim, norm_mode='instance', dropout=False, pad_mode=\"CONSTANT\"):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode)\n",
    "        self.conv2 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode, use_relu=False)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.conv1(x)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class ResNetGenerator(nn.Cell):\n",
    "    def __init__(self, input_channel=3, output_channel=64, n_layers=9, alpha=0.2, norm_mode='instance', dropout=False,\n",
    "                 pad_mode=\"CONSTANT\"):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        self.conv_in = ConvNormReLU(input_channel, output_channel, 7, 1, alpha, norm_mode, pad_mode=pad_mode)\n",
    "        self.down_1 = ConvNormReLU(output_channel, output_channel * 2, 3, 2, alpha, norm_mode)\n",
    "        self.down_2 = ConvNormReLU(output_channel * 2, output_channel * 4, 3, 2, alpha, norm_mode)\n",
    "        layers = [ResidualBlock(output_channel * 4, norm_mode, dropout=dropout, pad_mode=pad_mode)] * n_layers\n",
    "        self.residuals = nn.SequentialCell(layers)\n",
    "        self.up_2 = ConvNormReLU(output_channel * 4, output_channel * 2, 3, 2, alpha, norm_mode, transpose=True)\n",
    "        self.up_1 = ConvNormReLU(output_channel * 2, output_channel, 3, 2, alpha, norm_mode, transpose=True)\n",
    "        if pad_mode == \"CONSTANT\":\n",
    "            self.conv_out = nn.Conv2d(output_channel, 3, kernel_size=7, stride=1, pad_mode='pad',\n",
    "                                      padding=3, weight_init=weight_init)\n",
    "        else:\n",
    "            pad = nn.Pad(paddings=((0, 0), (0, 0), (3, 3), (3, 3)), mode=pad_mode)\n",
    "            conv = nn.Conv2d(output_channel, 3, kernel_size=7, stride=1, pad_mode='pad', weight_init=weight_init)\n",
    "            self.conv_out = nn.SequentialCell([pad, conv])\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_1(x)\n",
    "        output = self.conv_out(x)\n",
    "        return ops.tanh(output)\n",
    "\n",
    "# 实例化生成器\n",
    "net_rg_a = ResNetGenerator()\n",
    "# net_rg_a.update_parameters_name('net_rg_a.')\n",
    "\n",
    "net_rg_b = ResNetGenerator()\n",
    "# net_rg_b.update_parameters_name('net_rg_b.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建判别器\n",
    "\n",
    "判别器其实是一个二分类网络模型，输出判定该图像为真实图的概率。网络模型使用的是 Patch 大小为 70x70 的 PatchGANs 模型。通过一系列的 `Conv2d` 、 `BatchNorm2d` 和 `LeakyReLU` 层对其进行处理，最后通过 Sigmoid 激活函数得到最终概率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T03:27:11.592653Z",
     "start_time": "2023-03-07T03:27:11.492920Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "class Discriminator(nn.Cell):\n",
    "    def __init__(self, input_channel=3, output_channel=64, n_layers=3, alpha=0.2, norm_mode='instance'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = 4\n",
    "        layers = [nn.Conv2d(input_channel, output_channel, kernel_size, 2, pad_mode='pad', padding=1, weight_init=weight_init),\n",
    "                  nn.LeakyReLU(alpha)]\n",
    "        nf_mult = output_channel\n",
    "        for i in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** i, 8) * output_channel\n",
    "            layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 2, alpha, norm_mode, padding=1))\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8) * output_channel\n",
    "        layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 1, alpha, norm_mode, padding=1))\n",
    "        layers.append(nn.Conv2d(nf_mult, 1, kernel_size, 1, pad_mode='pad', padding=1, weight_init=weight_init))\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "# 判别器初始化\n",
    "net_d_a = Discriminator()\n",
    "# net_d_a.update_parameters_name('net_d_a.')\n",
    "\n",
    "net_d_b = Discriminator()\n",
    "# net_d_b.update_parameters_name('net_d_b.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器和损失函数\n",
    "\n",
    "根据不同模型需要单独的设置优化器，这是训练过程决定的。\n",
    "\n",
    "对生成器 $G$ 及其判别器 $D_{Y}$ ，目标损失函数定义为:\n",
    "\n",
    "$$L_{GAN}(G,D_Y,X,Y)=E_{y-p_{data}(y)}[logD_Y(y)]+E_{x-p_{data}(x)}[log(1-D_Y(G(x)))]$$\n",
    "\n",
    "其中 $G$ 试图生成看起来与 $Y$ 中的图像相似的图像 $G(x)$ ，而 $D_{Y}$ 的目标是区分翻译样本 $G(x)$ 和真实样本 $y$ ，生成器的目标是最小化这个损失函数以此来对抗判别器。即 $ min_{G} max_{D_{Y}}L_{GAN}(G,D_{Y} ,X,Y )$ 。\n",
    "\n",
    "单独的对抗损失不能保证所学函数可以将单个输入映射到期望的输出，为了进一步减少可能的映射函数的空间，学习到的映射函数应该是周期一致的，例如对于 $X$ 的每个图像 $x$ ，图像转换周期应能够将 $x$ 带回原始图像，可以称之为正向循环一致性，即 $x→G(x)→F(G(x))\\approx x$ 。对于 $Y$ ，类似的 $x→G(x)→F(G(x))\\approx x$ 。可以理解采用了一个循环一致性损失来激励这种行为。\n",
    "\n",
    "循环一致损失函数定义如下：\n",
    "\n",
    "$$L_{cyc}(G,F)=E_{x-p_{data}(x)}[\\Vert F(G(x))-x\\Vert_{1}]+E_{y-p_{data}(y)}[\\Vert G(F(y))-y\\Vert_{1}]$$\n",
    "\n",
    "循环一致损失能够保证重建图像 $F(G(x))$ 与输入图像 $x$ 紧密匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建生成器，判别器优化器\n",
    "optimizer_rg_a = nn.Adam(net_rg_a.trainable_params(), learning_rate=0.0002, beta1=0.5)\n",
    "optimizer_rg_b = nn.Adam(net_rg_b.trainable_params(), learning_rate=0.0002, beta1=0.5)\n",
    "\n",
    "optimizer_d_a = nn.Adam(net_d_a.trainable_params(), learning_rate=0.0002, beta1=0.5)\n",
    "optimizer_d_b = nn.Adam(net_d_b.trainable_params(), learning_rate=0.0002, beta1=0.5)\n",
    "\n",
    "# GAN网络损失函数，这里最后一层不使用sigmoid函数\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "l1_loss = nn.L1Loss(\"mean\")\n",
    "\n",
    "def gan_loss(predict, target):\n",
    "    target = ops.ones_like(predict) * target\n",
    "    loss = loss_fn(predict, target)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向计算\n",
    "\n",
    "搭建模型前向计算损失的过程，过程如下代码。\n",
    "\n",
    "为了减少模型振荡[1]，这里遵循 Shrivastava 等人的策略[2]，使用生成器生成图像的历史数据而不是生成器生成的最新图像数据来更新鉴别器。这里创建 `image_pool` 函数，保留了一个图像缓冲区，用于存储生成器生成前的50个图像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T03:32:21.516319Z",
     "start_time": "2023-03-07T03:32:21.501359Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "# 前向计算\n",
    "\n",
    "def generator(img_a, img_b):\n",
    "    fake_a = net_rg_b(img_b)\n",
    "    fake_b = net_rg_a(img_a)\n",
    "    rec_a = net_rg_b(fake_b)\n",
    "    rec_b = net_rg_a(fake_a)\n",
    "    identity_a = net_rg_b(img_a)\n",
    "    identity_b = net_rg_a(img_b)\n",
    "    return fake_a, fake_b, rec_a, rec_b, identity_a, identity_b\n",
    "\n",
    "lambda_a = 10.0\n",
    "lambda_b = 10.0\n",
    "lambda_idt = 0.5\n",
    "\n",
    "def generator_forward(img_a, img_b):\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    fake_a, fake_b, rec_a, rec_b, identity_a, identity_b = generator(img_a, img_b)\n",
    "    loss_g_a = gan_loss(net_d_b(fake_b), true)\n",
    "    loss_g_b = gan_loss(net_d_a(fake_a), true)\n",
    "    loss_c_a = l1_loss(rec_a, img_a) * lambda_a\n",
    "    loss_c_b = l1_loss(rec_b, img_b) * lambda_b\n",
    "    loss_idt_a = l1_loss(identity_a, img_a) * lambda_a * lambda_idt\n",
    "    loss_idt_b = l1_loss(identity_b, img_b) * lambda_b * lambda_idt\n",
    "    loss_g = loss_g_a + loss_g_b + loss_c_a + loss_c_b + loss_idt_a + loss_idt_b\n",
    "    return fake_a, fake_b, loss_g, loss_g_a, loss_g_b, loss_c_a, loss_c_b, loss_idt_a, loss_idt_b\n",
    "\n",
    "def generator_forward_grad(img_a, img_b):\n",
    "    _, _, loss_g, _, _, _, _, _, _ = generator_forward(img_a, img_b)\n",
    "    return loss_g\n",
    "\n",
    "def discriminator_forward(img_a, img_b, fake_a, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "    return loss_d\n",
    "\n",
    "def discriminator_forward_a(img_a, fake_a):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    return loss_d_a\n",
    "\n",
    "def discriminator_forward_b(img_b, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    return loss_d_b\n",
    "\n",
    "# 保留了一个图像缓冲区，用来存储之前创建的50个图像\n",
    "pool_size = 50\n",
    "def image_pool(images):\n",
    "    num_imgs = 0\n",
    "    image1 = []\n",
    "    if isinstance(images, Tensor):\n",
    "        images = images.asnumpy()\n",
    "    return_images = []\n",
    "    for image in images:\n",
    "        if num_imgs < pool_size:\n",
    "            num_imgs = num_imgs + 1\n",
    "            image1.append(image)\n",
    "            return_images.append(image)\n",
    "        else:\n",
    "            if random.uniform(0, 1) > 0.5:\n",
    "                random_id = random.randint(0, pool_size - 1)\n",
    "\n",
    "                tmp = image1[random_id].copy()\n",
    "                image1[random_id] = image\n",
    "                return_images.append(tmp)\n",
    "\n",
    "            else:\n",
    "                return_images.append(image)\n",
    "    output = Tensor(return_images, ms.float32)\n",
    "    if output.ndim != 4:\n",
    "        raise ValueError(\"img should be 4d, but get shape {}\".format(output.shape))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算梯度和反向传播\n",
    "\n",
    "其中梯度计算也是分开不同的模型来进行的，详情见如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindspore import value_and_grad\n",
    "\n",
    "# 实例化求梯度的方法\n",
    "grad_g_a = value_and_grad(generator_forward_grad, None, net_rg_a.trainable_params())\n",
    "grad_g_b = value_and_grad(generator_forward_grad, None, net_rg_b.trainable_params())\n",
    "\n",
    "grad_d_a = value_and_grad(discriminator_forward_a, None, net_d_a.trainable_params())\n",
    "grad_d_b = value_and_grad(discriminator_forward_b, None, net_d_b.trainable_params())\n",
    "\n",
    "# 计算生成器的梯度，反向传播更新参数\n",
    "def train_step_g(img_a, img_b):\n",
    "    net_d_a.set_grad(False)\n",
    "    net_d_b.set_grad(False)\n",
    "\n",
    "    fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib = generator_forward(img_a, img_b)\n",
    "\n",
    "    _, grads_g_a = grad_g_a(img_a, img_b)\n",
    "    _, grads_g_b = grad_g_b(img_a, img_b)\n",
    "    optimizer_rg_a(grads_g_a)\n",
    "    optimizer_rg_b(grads_g_b)\n",
    "\n",
    "    return fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib\n",
    "\n",
    "# 计算判别器的梯度，反向传播更新参数\n",
    "def train_step_d(img_a, img_b, fake_a, fake_b):\n",
    "    net_d_a.set_grad(True)\n",
    "    net_d_b.set_grad(True)\n",
    "\n",
    "    loss_d_a, grads_d_a = grad_d_a(img_a, fake_a)\n",
    "    loss_d_b, grads_d_b = grad_d_b(img_b, fake_b)\n",
    "\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "\n",
    "    optimizer_d_a(grads_d_a)\n",
    "    optimizer_d_b(grads_d_b)\n",
    "\n",
    "    return loss_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "训练分为两个主要部分：训练判别器和训练生成器，在前文的判别器损失函数中，论文采用了最小二乘损失代替负对数似然目标。\n",
    "\n",
    "- 训练判别器：训练判别器的目的是最大程度地提高判别图像真伪的概率。按照论文的方法需要训练判别器来最小化 $E_{y-p_{data}(y)}[(D(y)-1)^2]$ ；\n",
    "\n",
    "- 训练生成器：如 CycleGAN 论文所述，我们希望通过最小化 $E_{x-p_{data}(x)}[(D(G(x)-1)^2]$ 来训练生成器，以产生更好的虚假图像。\n",
    "\n",
    "下面定义了生成器和判别器的训练过程：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mindspore import Tensor, save_checkpoint\n",
    "from mindspore import dtype\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "def load_ckpt(net, ckpt_dir):\n",
    "    param_GA = load_checkpoint(ckpt_dir)\n",
    "    load_param_into_net(net, param_GA)\n",
    "\n",
    "epochs = 1\n",
    "save_step_num = 200\n",
    "save_checkpoint_epochs = 1\n",
    "save_ckpt_dir = './train_ckpt_outputs/'\n",
    "save_img_dir='./image_outputs/'\n",
    "resume=True\n",
    "\n",
    "if(resume):\n",
    "    g_a_ckpt = './ckpt/G_A_120.ckpt'\n",
    "    g_b_ckpt = './ckpt/G_B_120.ckpt'\n",
    "    d_a_ckpt = './ckpt/D_A_120.ckpt'\n",
    "    d_b_ckpt = './ckpt/D_B_120.ckpt'\n",
    "\n",
    "    load_ckpt(net_rg_a, g_a_ckpt)\n",
    "    load_ckpt(net_rg_b, g_b_ckpt)\n",
    "    load_ckpt(net_d_a, d_a_ckpt)\n",
    "    load_ckpt(net_d_b, d_b_ckpt)\n",
    "    \n",
    "print('Start training!')\n",
    "\n",
    "\n",
    "\n",
    "def train_loop(epoch):\n",
    "    g_loss = []\n",
    "    d_loss = []\n",
    "    start_time_e = time.time()\n",
    "    for step, data in enumerate(cyclegan_ds.create_dict_iterator()):\n",
    "        start_time_s = time.time()\n",
    "        img_a = data[\"image_A\"]\n",
    "        img_b = data[\"image_B\"]\n",
    "        res_g = train_step_g(img_a, img_b)\n",
    "        fake_a = res_g[0]\n",
    "        fake_b = res_g[1]\n",
    "        if step==0:\n",
    "            os.makedirs(save_img_dir, exist_ok=True)\n",
    "            img_a_pil=Image.fromarray((img_a[0] * 0.5 * 255 + 0.5 * 255).astype(np.uint8).transpose((1, 2, 0)).asnumpy())\n",
    "            img_b_pil=Image.fromarray((img_b[0] * 0.5 * 255 + 0.5 * 255).astype(np.uint8).transpose((1, 2, 0)).asnumpy())\n",
    "            fake_a_pil=Image.fromarray((fake_a[0] * 0.5 * 255 + 0.5 * 255).astype(np.uint8).transpose((1, 2, 0)).asnumpy())\n",
    "            fake_b_pil=Image.fromarray((fake_b[0] * 0.5 * 255 + 0.5 * 255).astype(np.uint8).transpose((1, 2, 0)).asnumpy())\n",
    "\n",
    "            img_a_pil.save(f\"./{save_img_dir}/{epoch}_img_a.jpg\")\n",
    "            img_b_pil.save(f\"./{save_img_dir}/{epoch}_img_b.jpg\")\n",
    "            fake_a_pil.save(f\"./{save_img_dir}/{epoch}_fake_a.jpg\")\n",
    "            fake_b_pil.save(f\"./{save_img_dir}/{epoch}_fake_b.jpg\")\n",
    "            \n",
    "        res_d = train_step_d(img_a, img_b, image_pool(fake_a), image_pool(fake_b))\n",
    "        loss_d = float(res_d.asnumpy())\n",
    "        step_time = time.time() - start_time_s\n",
    "\n",
    "        res = []\n",
    "        for item in res_g[2:]:\n",
    "            res.append(float(item.asnumpy()))\n",
    "        g_loss.append(res[0])\n",
    "        d_loss.append(loss_d)\n",
    "\n",
    "        if step % save_step_num == 0:\n",
    "            print(f\"Epoch:[{int(epoch + 1):>3d}/{int(epochs):>3d}], \"\n",
    "                  f\"step:[{int(step):>4d}/{int(datasize):>4d}], \"\n",
    "                  f\"time:{step_time:>3f}s,\\n\"\n",
    "                  f\"loss_g:{res[0]:.2f}, loss_d:{loss_d:.2f}, \"\n",
    "                  f\"loss_g_a: {res[1]:.2f}, loss_g_b: {res[2]:.2f}, \"\n",
    "                  f\"loss_c_a: {res[3]:.2f}, loss_c_b: {res[4]:.2f}, \"\n",
    "                  f\"loss_idt_a: {res[5]:.2f}, loss_idt_b: {res[6]:.2f}\")\n",
    "\n",
    "    epoch_cost = time.time() - start_time_e\n",
    "    per_step_time = epoch_cost / datasize\n",
    "    mean_loss_d, mean_loss_g = sum(d_loss) / datasize, sum(g_loss) / datasize\n",
    "\n",
    "    print(f\"Epoch:[{int(epoch + 1):>3d}/{int(epochs):>3d}], \"\n",
    "          f\"epoch time:{epoch_cost:.2f}s, per step time:{per_step_time:.2f}, \"\n",
    "          f\"mean_g_loss:{mean_loss_g:.2f}, mean_d_loss:{mean_loss_d :.2f}\")\n",
    "\n",
    "    if epoch % save_checkpoint_epochs == 0:\n",
    "        os.makedirs(save_ckpt_dir, exist_ok=True)\n",
    "        save_checkpoint(net_rg_a, os.path.join(save_ckpt_dir, f\"g_a_{epoch}.ckpt\"))\n",
    "        save_checkpoint(net_rg_b, os.path.join(save_ckpt_dir, f\"g_b_{epoch}.ckpt\"))\n",
    "        save_checkpoint(net_d_a, os.path.join(save_ckpt_dir, f\"d_a_{epoch}.ckpt\"))\n",
    "        save_checkpoint(net_d_b, os.path.join(save_ckpt_dir, f\"d_b_{epoch}.ckpt\"))\n",
    "\n",
    "            \n",
    "for t in range(epochs):\n",
    "    train_loop(t)\n",
    "    \n",
    "\n",
    "print('End of training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理\n",
    "\n",
    "下面我们通过加载生成器网络模型参数文件来对原图进行风格迁移，结果中第一行为原图，第二行为对应生成的结果图。配合边缘检测模型可以实现从原图提取线稿图的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 边缘检测Dexined模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore import nn, ops\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.amp import auto_mixed_precision\n",
    "from mindspore.common import initializer as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"DexiNed边缘检测数据集\"\"\"\n",
    "class Test_Dataset():\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, data_root, mean_bgr, image_size):\n",
    "        self.data = []\n",
    "        imgs_ = os.listdir(data_root)\n",
    "        self.names = []\n",
    "        self.filenames = []\n",
    "        for img in imgs_:\n",
    "            if img.endswith(\".png\") or img.endswith(\".jpg\"):\n",
    "                dir = os.path.join(data_root, img)\n",
    "                self.names.append(dir)\n",
    "                self.filenames.append(img)\n",
    "        self.mean_bgr = mean_bgr\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.names[idx], cv2.IMREAD_COLOR)\n",
    "        im_shape = (image.shape[0], image.shape[1])\n",
    "        image = self.transform(img=image)\n",
    "        return image, self.filenames[idx], im_shape\n",
    "\n",
    "    def transform(self, img):\n",
    "        img = cv2.resize(img, (self.image_size, self.image_size))\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"DexiNed 网络结构\"\"\"\n",
    "\n",
    "def weight_init(net):\n",
    "    for name, param in net.parameters_and_names():\n",
    "        if 'weight' in name:\n",
    "            param.set_data(\n",
    "                init.initializer(\n",
    "                    init.XavierNormal(),\n",
    "                    param.shape,\n",
    "                    param.dtype))\n",
    "        if 'bias' in name:\n",
    "            param.set_data(init.initializer('zeros', param.shape, param.dtype))\n",
    "\n",
    "\n",
    "class CoFusion(nn.Cell):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_ch, 64, kernel_size=3,\n",
    "            stride=1, padding=1, has_bias=True,\n",
    "            pad_mode=\"pad\", weight_init=init.XavierNormal())\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            64, 64, kernel_size=3,\n",
    "            stride=1, padding=1, has_bias=True,\n",
    "            pad_mode=\"pad\", weight_init=init.XavierNormal())\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            64, out_ch, kernel_size=3,\n",
    "            stride=1, padding=1, has_bias=True,\n",
    "            pad_mode=\"pad\", weight_init=init.XavierNormal())\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm_layer1 = nn.GroupNorm(4, 64)\n",
    "        self.norm_layer2 = nn.GroupNorm(4, 64)\n",
    "\n",
    "    def construct(self, x):\n",
    "        attn = self.relu(self.norm_layer1(self.conv1(x)))\n",
    "        attn = self.relu(self.norm_layer2(self.conv2(attn)))\n",
    "        attn = ops.softmax(self.conv3(attn), axis=1)\n",
    "\n",
    "        return ((x * attn).sum(1)).expand_dims(1)\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Cell):\n",
    "    def __init__(self, input_features, out_features):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_features, out_features, kernel_size=3,\n",
    "            stride=1, padding=2, pad_mode=\"pad\",\n",
    "            has_bias=True, weight_init=init.XavierNormal())\n",
    "        self.norm1 = nn.BatchNorm2d(out_features)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_features, out_features, kernel_size=3,\n",
    "            stride=1, pad_mode=\"pad\", has_bias=True,\n",
    "            weight_init=init.XavierNormal())\n",
    "        self.norm2 = nn.BatchNorm2d(out_features)\n",
    "        self.relu = ops.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x1, x2 = x\n",
    "        x1 = self.conv1(self.relu(x1))\n",
    "        x1 = self.norm1(x1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        new_features = self.norm2(x1)\n",
    "        return 0.5 * (new_features + x2), x2\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Cell):\n",
    "    def __init__(self, num_layers, input_features, out_features):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        self.denselayer1 = _DenseLayer(input_features, out_features)\n",
    "        input_features = out_features\n",
    "        self.denselayer2 = _DenseLayer(input_features, out_features)\n",
    "        if num_layers == 3:\n",
    "            self.denselayer3 = _DenseLayer(input_features, out_features)\n",
    "            self.layers = nn.SequentialCell(\n",
    "                [self.denselayer1, self.denselayer2, self.denselayer3])\n",
    "        else:\n",
    "            self.layers = nn.SequentialCell(\n",
    "                [self.denselayer1, self.denselayer2])\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpConvBlock(nn.Cell):\n",
    "    def __init__(self, in_features, up_scale):\n",
    "        super(UpConvBlock, self).__init__()\n",
    "        self.up_factor = 2\n",
    "        self.constant_features = 16\n",
    "\n",
    "        layers = self.make_deconv_layers(in_features, up_scale)\n",
    "\n",
    "        assert layers is not None, layers\n",
    "        self.features = nn.SequentialCell(*layers)\n",
    "\n",
    "    def make_deconv_layers(self, in_features, up_scale):\n",
    "        layers = []\n",
    "        all_pads = [0, 0, 1, 3, 7]\n",
    "        for i in range(up_scale):\n",
    "            kernel_size = 2 ** up_scale\n",
    "            pad = all_pads[up_scale]  # kernel_size-1\n",
    "            out_features = self.compute_out_features(i, up_scale)\n",
    "            layers.append(nn.Conv2d(\n",
    "                in_features, out_features,\n",
    "                1, has_bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Conv2dTranspose(\n",
    "                out_features, out_features, kernel_size,\n",
    "                stride=2, padding=pad, pad_mode=\"pad\",\n",
    "                has_bias=True, weight_init=init.XavierNormal()))\n",
    "            in_features = out_features\n",
    "        return layers\n",
    "\n",
    "    def compute_out_features(self, idx, up_scale):\n",
    "        return 1 if idx == up_scale - 1 else self.constant_features\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "class SingleConvBlock(nn.Cell):\n",
    "    def __init__(self, in_features, out_features, stride,\n",
    "                 use_bs=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.use_bn = use_bs\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_features,\n",
    "            out_features,\n",
    "            1,\n",
    "            stride=stride,\n",
    "            pad_mode=\"pad\",\n",
    "            has_bias=True,\n",
    "            weight_init=init.XavierNormal())\n",
    "        self.bn = nn.BatchNorm2d(out_features)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConvBlock(nn.Cell):\n",
    "    def __init__(self, in_features, mid_features,\n",
    "                 out_features=None,\n",
    "                 stride=1,\n",
    "                 use_act=True):\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "\n",
    "        self.use_act = use_act\n",
    "        if out_features is None:\n",
    "            out_features = mid_features\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_features,\n",
    "            mid_features,\n",
    "            3,\n",
    "            padding=1,\n",
    "            stride=stride,\n",
    "            pad_mode=\"pad\",\n",
    "            has_bias=True,\n",
    "            weight_init=init.XavierNormal())\n",
    "        self.bn1 = nn.BatchNorm2d(mid_features)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            mid_features,\n",
    "            out_features,\n",
    "            3,\n",
    "            padding=1,\n",
    "            pad_mode=\"pad\",\n",
    "            has_bias=True,\n",
    "            weight_init=init.XavierNormal())\n",
    "        self.bn2 = nn.BatchNorm2d(out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.use_act:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class maxpooling(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(maxpooling, self).__init__()\n",
    "        self.pad = nn.Pad(((0,0),(0,0),(1,1),(1,1)), mode=\"SYMMETRIC\")\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='valid')\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DexiNed(nn.Cell):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DexiNed, self).__init__()\n",
    "        self.block_1 = DoubleConvBlock(3, 32, 64, stride=2,)\n",
    "        self.block_2 = DoubleConvBlock(64, 128, use_act=False)\n",
    "        self.dblock_3 = _DenseBlock(2, 128, 256)  # [128,256,100,100]\n",
    "        self.dblock_4 = _DenseBlock(3, 256, 512)\n",
    "        self.dblock_5 = _DenseBlock(3, 512, 512)\n",
    "        self.dblock_6 = _DenseBlock(3, 512, 256)\n",
    "\n",
    "        self.maxpool = maxpooling()\n",
    "\n",
    "        self.side_1 = SingleConvBlock(64, 128, 2)\n",
    "        self.side_2 = SingleConvBlock(128, 256, 2)\n",
    "        self.side_3 = SingleConvBlock(256, 512, 2)\n",
    "        self.side_4 = SingleConvBlock(512, 512, 1)\n",
    "        self.side_5 = SingleConvBlock(512, 256, 1)  \n",
    "        \n",
    "        # right skip connections, figure in Journal paper\n",
    "        self.pre_dense_2 = SingleConvBlock(128, 256, 2)\n",
    "        self.pre_dense_3 = SingleConvBlock(128, 256, 1)\n",
    "        self.pre_dense_4 = SingleConvBlock(256, 512, 1)\n",
    "        self.pre_dense_5 = SingleConvBlock(512, 512, 1)\n",
    "        self.pre_dense_6 = SingleConvBlock(512, 256, 1)\n",
    "\n",
    "        self.up_block_1 = UpConvBlock(64, 1)\n",
    "        self.up_block_2 = UpConvBlock(128, 1)\n",
    "        self.up_block_3 = UpConvBlock(256, 2)\n",
    "        self.up_block_4 = UpConvBlock(512, 3)\n",
    "        self.up_block_5 = UpConvBlock(512, 4)\n",
    "        self.up_block_6 = UpConvBlock(256, 4)\n",
    "        self.block_cat = SingleConvBlock(6, 1, stride=1, use_bs=False)\n",
    "\n",
    "    def slice(self, tensor, slice_shape):\n",
    "        t_shape = tensor.shape\n",
    "        height, width = slice_shape\n",
    "        if t_shape[-1] != slice_shape[-1]:\n",
    "            new_tensor = ops.interpolate(\n",
    "                tensor,\n",
    "                sizes=(height, width),\n",
    "                mode='bilinear',\n",
    "                coordinate_transformation_mode=\"half_pixel\")\n",
    "        else:\n",
    "            new_tensor = tensor\n",
    "        return new_tensor\n",
    "\n",
    "    def construct(self, x):\n",
    "        assert x.ndim == 4, x.shape\n",
    "\n",
    "        # Block 1\n",
    "        block_1 = self.block_1(x)\n",
    "        block_1_side = self.side_1(block_1)\n",
    "\n",
    "        # Block 2\n",
    "        block_2 = self.block_2(block_1)\n",
    "        block_2_down = self.maxpool(block_2)\n",
    "        block_2_add = block_2_down + block_1_side\n",
    "        block_2_side = self.side_2(block_2_add)\n",
    "        # Block 3\n",
    "        block_3_pre_dense = self.pre_dense_3(block_2_down)\n",
    "        block_3, _ = self.dblock_3([block_2_add, block_3_pre_dense])\n",
    "        block_3_down = self.maxpool(block_3)  # [128,256,50,50]\n",
    "        block_3_add = block_3_down + block_2_side\n",
    "        block_3_side = self.side_3(block_3_add)\n",
    "        # Block 4\n",
    "        block_2_resize_half = self.pre_dense_2(block_2_down)\n",
    "        block_4_pre_dense = self.pre_dense_4(\n",
    "            block_3_down + block_2_resize_half)\n",
    "        block_4, _ = self.dblock_4([block_3_add, block_4_pre_dense])\n",
    "        block_4_down = self.maxpool(block_4)\n",
    "        block_4_add = block_4_down + block_3_side\n",
    "        block_4_side = self.side_4(block_4_add)\n",
    "        # Block 5\n",
    "        block_5_pre_dense = self.pre_dense_5(\n",
    "            block_4_down)  # block_5_pre_dense_512 +block_4_down\n",
    "        block_5, _ = self.dblock_5([block_4_add, block_5_pre_dense])\n",
    "        block_5_add = block_5 + block_4_side\n",
    "        # Block 6\n",
    "        block_6_pre_dense = self.pre_dense_6(block_5)\n",
    "        block_6, _ = self.dblock_6([block_5_add, block_6_pre_dense])\n",
    "        # upsampling blocks\n",
    "        out_1 = self.up_block_1(block_1)\n",
    "        out_2 = self.up_block_2(block_2)\n",
    "        out_3 = self.up_block_3(block_3)\n",
    "        out_4 = self.up_block_4(block_4)\n",
    "        out_5 = self.up_block_5(block_5)\n",
    "        out_6 = self.up_block_6(block_6)\n",
    "        results = [out_1, out_2, out_3, out_4, out_5, out_6]\n",
    "        # concatenate multiscale outputs\n",
    "        op = ops.Concat(1)\n",
    "        block_cat = op(results)\n",
    "\n",
    "        block_cat = self.block_cat(block_cat)  # Bx1xHxW\n",
    "        results.append(block_cat)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''将输入图像规格化到指定范围'''\n",
    "def image_normalization(img, img_min=0, img_max=255, epsilon=1e-12):\n",
    "    img = np.float32(img)\n",
    "    img = (img - np.min(img)) * (img_max - img_min) / \\\n",
    "        ((np.max(img) - np.min(img)) + epsilon) + img_min\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''对DexiNed模型的输出数据进行后处理'''\n",
    "def fuse_DNoutput(img):\n",
    "    edge_maps = []\n",
    "    tensor = img\n",
    "    for i in tensor:\n",
    "        sigmoid = ops.Sigmoid()\n",
    "        output = sigmoid(i).numpy()\n",
    "        edge_maps.append(output)\n",
    "    tensor = np.array(edge_maps)\n",
    "    idx = 0\n",
    "    tmp = tensor[:, idx, ...]\n",
    "    tmp = np.squeeze(tmp)\n",
    "    preds = []\n",
    "    for i in range(tmp.shape[0]):\n",
    "        tmp_img = tmp[i]\n",
    "        tmp_img = np.uint8(image_normalization(tmp_img))\n",
    "        tmp_img = cv2.bitwise_not(tmp_img)\n",
    "        preds.append(tmp_img)\n",
    "        if i == 6:\n",
    "            fuse = tmp_img\n",
    "            fuse = fuse.astype(np.uint8)\n",
    "    idx += 1\n",
    "    return fuse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"DexiNed 检测.\"\"\"\n",
    "\n",
    "def test(imgs,dexined_ckpt):\n",
    "    \n",
    "    if not os.path.isfile(dexined_ckpt):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Checkpoint file not found: {dexined_ckpt}\")\n",
    "    print(f\"DexiNed ckpt path : {dexined_ckpt}\")\n",
    "    # os.makedirs(dexined_output_dir, exist_ok=True)\n",
    "    model = DexiNed()\n",
    "    # model = auto_mixed_precision(model, 'O2')\n",
    "    ms.load_checkpoint(dexined_ckpt, model)\n",
    "    model.set_train(False)\n",
    "    preds = []\n",
    "    origin = []\n",
    "    total_duration = []\n",
    "    print('Start dexined testing....')\n",
    "    for img in imgs.create_dict_iterator():\n",
    "        filename = str(img[\"names\"])[2:-2]\n",
    "        # print(filename)\n",
    "        # output_dir_f = os.path.join(dexined_output_dir, filename)\n",
    "        image = img[\"data\"]\n",
    "        origin.append(filename)\n",
    "        end = time.perf_counter()\n",
    "        pred = model(image)\n",
    "        img_h = img[\"img_shape\"][0, 0]\n",
    "        img_w = img[\"img_shape\"][0, 1]\n",
    "        pred = fuse_DNoutput(pred)\n",
    "        dexi_img = cv2.resize(\n",
    "            pred, (int(img_w.asnumpy()), int(img_h.asnumpy())))\n",
    "        # cv2.imwrite(\"output.jpg\", dexi_img)\n",
    "        tmp_duration = time.perf_counter() - end\n",
    "        total_duration.append(tmp_duration)\n",
    "        preds.append(pred)\n",
    "    total_duration_f = np.sum(np.array(total_duration))\n",
    "    print(\"FPS: %f.4\" % (len(total_duration) / total_duration_f))\n",
    "    return preds,origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mindspore.dataset as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import mindspore.dataset.vision as vision\n",
    "from mindspore.dataset import transforms\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "# 加载权重文件\n",
    "def load_ckpt(net, ckpt_dir):\n",
    "    param_GA = load_checkpoint(ckpt_dir)\n",
    "    load_param_into_net(net, param_GA)\n",
    "\n",
    "    \n",
    "#模型参数地址\n",
    "g_a_ckpt = './ckpt/G_A_120.ckpt'\n",
    "dexined_ckpt = \"./ckpt/dexined.ckpt\"\n",
    "\n",
    "#图片输入地址\n",
    "img_path='./ckpt/jt'\n",
    "#输出地址\n",
    "save_path='./result'\n",
    "\n",
    "load_ckpt(net_rg_a, g_a_ckpt)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "# 图片推理\n",
    "fig = plt.figure(figsize=(16, 4), dpi=64)\n",
    "def eval_data(dir_path, net, a):\n",
    "    my_dataset = Test_Dataset(\n",
    "        dir_path, mean_bgr=[167.15, 146.07, 124.62], image_size=512)\n",
    "    \n",
    "    dataset = ds.GeneratorDataset(\n",
    "        my_dataset, column_names=[\n",
    "            \"data\", \"names\", \"img_shape\"])\n",
    "    dataset = dataset.batch(1, drop_remainder=True)\n",
    "    pres ,origin= test(dataset,dexined_ckpt)\n",
    "    for i, data in enumerate(pres):\n",
    "        img =ms.Tensor((np.array([data,data,data])/255-0.5)*2).unsqueeze(0)\n",
    "        fake = net(img.to(ms.float32))\n",
    "        \n",
    "        fake = (fake[0] * 0.5 * 255 + 0.5 * 255).astype(np.uint8).transpose((1, 2, 0))\n",
    "        img = (Image.open(os.path.join(img_path,origin[i])).convert('RGB'))\n",
    "\n",
    "        fake_pil=Image.fromarray(fake.asnumpy())\n",
    "        fake_pil.save(f\"{save_path}/{i}.jpg\")\n",
    "        \n",
    "        if i<8:\n",
    "            fig.add_subplot(2, 8, min(i+1+a, 16))\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(np.array(img))\n",
    "\n",
    "            fig.add_subplot(2, 8, min(i+9+a, 16))\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(fake.asnumpy())\n",
    "\n",
    "eval_data(img_path,net_rg_a, 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "[1] I. Goodfellow. NIPS 2016 tutorial: Generative ad-versarial networks. arXiv preprint arXiv:1701.00160,2016. 2, 4, 5\n",
    "\n",
    "[2] A. Shrivastava, T. Pfister, O. Tuzel, J. Susskind, W. Wang, R. Webb. Learning from simulated and unsupervised images through adversarial training. In CVPR, 2017. 3, 5, 6, 7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
