{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215c577e",
   "metadata": {},
   "source": [
    "## 基于MindSpore的恶性皮肤肿瘤识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb897bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 实验介绍\n",
    "\n",
    "本实验旨在使用MindSpore框架在包含4个类别的数据集上，进行模型微调以训练ResNet50模型，实现皮肤病识别模型；\n",
    "\n",
    "我们将利用MindSpore model_zoo中提供的ResNet50模型定义，通过昇思大模型平台进行模型的训练和优化；\n",
    "\n",
    "### 1.1 实验目标\n",
    "1. 掌握使用MindSpore框架进行深度学习模型训练的基本流程；\n",
    "2. 理解ResNet50模型结构及其在图像分类任务中的应用；\n",
    "3. 学习如何针对特定数据集（皮肤病图像）调整和优化模型参数；\n",
    "\n",
    "### 1.2 使用工具介绍\n",
    "1. **MindSpore框架**：开源深度学习框架，支持端、边、云多种场景，旨在为用户提供全场景AI解决方案；\n",
    "2. **ResNet50模型**：深度残差网络，通过引入残差学习解决了深度网络训练中的梯度消失问题，是图像识别领域广泛使用的模型之一；\n",
    "3. **昇思大模型平台**：一个基于昇思Mindspore的深度学习平台，提供强大的计算资源和丰富的模型库；\n",
    "\n",
    "### 1.3 实验步骤\n",
    "1. **数据准备**：收集并预处理皮肤病图像数据集，确保数据质量满足训练需求。\n",
    "2. **模型选择**：使用MindSpore model_zoo中的ResNet50模型作为基础模型。\n",
    "3. **模型训练**：在昇思大模型平台上配置训练参数，启动模型训练过程。\n",
    "4. **性能评估**：通过验证集评估模型性能，调整超参数以优化模型。\n",
    "5. **模型部署**：将训练好的模型部署到实际应用中，进行皮肤病识别。\n",
    "\n",
    "### 1.4 预备知识\n",
    "1. 熟练使用Python，了解Shell及Linux操作系统基本知识；\n",
    "2. 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略、Checkpoint等；\n",
    "3. 了解并熟悉MindSpore AI框架，MindSpore官网：https://www.mindspore.cn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68706b31-7dea-498f-a7eb-7a3e079b73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.3.0，如需更换mindspore版本，可更改下面 MINDSPORE_VERSION 变量\n",
    "!pip uninstall mindspore -y\n",
    "%env MINDSPORE_VERSION=2.3.0\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/${MINDSPORE_VERSION}/MindSpore/unified/aarch64/mindspore-${MINDSPORE_VERSION}-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.mirrors.ustc.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32898bb-55b1-41ef-971b-199495610b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前 mindspore 版本\n",
    "!pip show mindspore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed6e6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 数据集处理\n",
    "\n",
    "### 2.1 数据集介绍\n",
    "\n",
    "数据集共有四类皮肤图片，分别为Basal Cell Carcinoma（基底细胞癌）、Melanoma（黑色素瘤）、Pigmented Benign Keratosis（色素性良性角化病）、Nevus（痣）四种；\n",
    "\n",
    "- 基底细胞癌：是一种常见的皮肤癌，起源于表皮的基底细胞层，通常不会转移到身体其他部位，但如果不治疗，可能会局部侵袭并破坏周围组织；\n",
    "- 黑色素瘤：是一种较为严重的皮肤癌，起源于皮肤中的黑色素细胞，可以迅速扩散到身体其他部位，因此早期发现和治疗至关重要；\n",
    "- 痣：为色素痣，是皮肤上的一种色素沉着区域，通常为良性，可以是先天性的，也可以是后天发展的；\n",
    "- 色素性良性角化病：是一种良性皮肤病变，表现为皮肤上的小色素斑块，通常不会引起健康问题，但有时可能会被误认为是黑色素瘤；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef79fbf",
   "metadata": {},
   "source": [
    "### 2.2 数据集获取和整理\n",
    "\n",
    "数据集这里已经上传到昇思大模型社区内，链接为：https://xihe.mindspore.cn/datasets/knoka/pifudata_Maker/tree\n",
    "\n",
    "这里可以用git快速获取，下载后存储在pifudata_Maker文件夹内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc44b5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://source-xihe-mindspore.osinfra.cn/knoka/pifudata_Maker.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1c9cf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 解压数据集pifudata_Maker/skin-cancer-detection.tar 并存储到pifudata_Maker文件夹内\n",
    "!tar -xv -f pifudata_Maker/skin-cancer-detection.tar -C pifudata_Maker/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fb5fb-3291-42ea-8161-bd52850ccf33",
   "metadata": {
    "tags": []
   },
   "source": [
    "下载后可以看到我们的数据集为如下形式，其中`dataset_dir`  根目录名称可以根据需要进行更改。\n",
    "\n",
    "训练图像目录\n",
    "`train`  包含用于训练的各个皮肤图像类别的目录\n",
    "- `class1`\n",
    "- `class2`\n",
    "- `class3`\n",
    "- `class4`\n",
    "\n",
    "验证图像目录\n",
    "`val`  包含用于验证的各个皮瘤图像类别的目录\n",
    "- `class1`\n",
    "- `class2`\n",
    "- `class3`\n",
    "- `class4`\n",
    "\n",
    "下面部分代码则是将文件夹英文名转为数字0-3命名，至于为什么为这种格式，则源由于图像分类任务通常为将数据集组织成文件夹，其中每个文件夹的名称代表一个类别；\n",
    "\n",
    "因此会期望每个文件夹名称是一个可以识别的标签，如果文件夹名称是数字，则可以将其直接作为类别标签，因为在训练过程中模型需要将输入数据（图像）与输出标签（类别）关联起来；\n",
    "\n",
    "将疾病名称重命名为对应的编号后，MindSpore提供一种简便的方式来加载和处理数据集，即通过文件夹名称自动将图片分配到对应的类别；因此确保数据集的转换如此，可以简化数据加载和处理过程，直接使用文件夹名称（即编号）作为图像的标签，而不需要额外的映射步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d992629-94d5-41ec-92c2-5d2d31ea12a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义疾病名称和编号的映射\n",
    "diseases = {\n",
    "    0: \"basal_cell_carcinoma\",\n",
    "    1: \"melanoma\",\n",
    "    2: \"nevus\",\n",
    "    3: \"pigmented_benign_keratosis\",\n",
    "}\n",
    "\n",
    "# 定义目标文件夹路径\n",
    "target_directory = \"pifudata_Maker/images/\"  # 替换为你的文件夹路径\n",
    "\n",
    "# 遍历每个疾病名称和编号\n",
    "for folder in [\"train\", \"val\"]:\n",
    "    folder_path = os.path.join(target_directory, folder)\n",
    "    print(folder_path)\n",
    "    for number,disease in diseases.items():\n",
    "        # 构造完整的旧文件夹路径\n",
    "        old_folder_path = os.path.join(folder_path, disease)\n",
    "        \n",
    "        # 检查旧文件夹是否存在\n",
    "        if not os.path.exists(old_folder_path):\n",
    "            print(f\"Folder not found: {old_folder_path}\")\n",
    "            continue\n",
    "        \n",
    "        # 构造新的文件夹名称\n",
    "        new_folder_name = f\"{number}\"\n",
    "        \n",
    "        # 构造完整的新文件夹路径\n",
    "        new_folder_path = os.path.join(folder_path, new_folder_name)\n",
    "        \n",
    "        # 重命名文件夹\n",
    "        os.rename(old_folder_path, new_folder_path)\n",
    "        print(f\"Renamed {old_folder_path} to {new_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c288319-08a4-49fe-a4f4-398b59fa1bcc",
   "metadata": {},
   "source": [
    "### 2.3 数据集比例可视化\n",
    "\n",
    "通过对数据集进行可视化展示，便于对数据进行直观的查看，为后续超参数的设置等做出帮助；\n",
    "\n",
    "共有Basal Cell Carcinoma（基底细胞癌）、Melanoma（黑色素瘤）、Pigmented Benign Keratosis（色素性良性角化病）、Nevus（痣）四种皮肤；\n",
    "\n",
    "其中Nevus训练集图片为357张、Melanoma训练集图片为438张、Pigmented Benign Keratosis训练集图片为462张、Basal Cell Carcinoma训练集图片为376张，四者验证集均为16张；\n",
    "\n",
    "\n",
    "![image.png](./images/tumour_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2db62-30c6-4ce1-a044-f282cc2417d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 疾病编号到名称的映射\n",
    "diseases = {\n",
    "    0: \"basal_cell_carcinoma\",\n",
    "    1: \"melanoma\",\n",
    "    2: \"nevus\",\n",
    "    3: \"pigmented_benign_keratosis\",\n",
    "}\n",
    "\n",
    "# 数据集目录路径\n",
    "data_path_train = \"pifudata_Maker/images/train\"\n",
    "data_path_val = \"pifudata_Maker/images/val\"\n",
    "\n",
    "# 初始化一个字典来存储每个类别的文件数量\n",
    "file_counts_train = {}\n",
    "file_counts_val = {}\n",
    "\n",
    "# 遍历训练数据文件夹\n",
    "for folder_name in os.listdir(data_path_train):\n",
    "    folder_path = os.path.join(data_path_train, folder_name)\n",
    "    # 确保是文件夹\n",
    "    if os.path.isdir(folder_path):\n",
    "        # 计算文件夹内的文件数量\n",
    "        count = len(os.listdir(folder_path))\n",
    "        # 使用疾病编号作为字典的键\n",
    "        file_counts_train[diseases.get(folder_name, folder_name)] = count\n",
    "\n",
    "# 遍历验证数据文件夹\n",
    "for folder_name in os.listdir(data_path_val):\n",
    "    folder_path = os.path.join(data_path_val, folder_name)\n",
    "    # 确保是文件夹\n",
    "    if os.path.isdir(folder_path):\n",
    "        # 计算文件夹内的文件数量\n",
    "        count = len(os.listdir(folder_path))\n",
    "        # 使用疾病编号作为字典的键\n",
    "        file_counts_val[diseases.get(folder_name, folder_name)] = count\n",
    "\n",
    "# 获取训练集的疾病名称列表\n",
    "train_categories = list(file_counts_train.keys())\n",
    "\n",
    "# 使用matplotlib生成条形图\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 绘制训练集的条形图\n",
    "train_bars = plt.bar(train_categories, file_counts_train.values(), width=0.4, color='blue', label='Train')\n",
    "\n",
    "# 绘制验证集的条形图，错开位置\n",
    "val_bars = plt.bar([train_categories.index(cat) + 0.4 for cat in train_categories], [file_counts_val.get(cat, 0) for cat in train_categories], width=0.4, color='green', label='Validation')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 使用疾病名称作为X轴标签\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Training and Validation Datasets')\n",
    "\n",
    "print(train_categories)\n",
    "\n",
    "train_list = [diseases[int(i)] for i in train_categories]\n",
    "print(train_list)\n",
    "\n",
    "plt.xticks([train_categories.index(cat) + 0.2 for cat in train_categories], [diseases[int(i)] for i in train_categories], rotation=30,fontsize='small')\n",
    "\n",
    "# 在柱形条上面显示数量\n",
    "for i, (train_bar, val_bar) in enumerate(zip(train_bars, val_bars)):\n",
    "    train_height = train_bar.get_height()\n",
    "    val_height = val_bar.get_height() if val_bar else 0\n",
    "    plt.text(train_bar.get_x() + train_bar.get_width() / 2, train_height, '{}'.format(train_height), ha='center', va='bottom')\n",
    "    plt.text(val_bar.get_x() + val_bar.get_width() / 2, val_height, '{}'.format(val_height), ha='center', va='bottom') if val_bar else None\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd808d",
   "metadata": {},
   "source": [
    "### 2.4 数据加载\n",
    "\n",
    " - 使用MindSpore框架的mindspore.dataset模块来加载和预处理图像数据集，以便进行模型训练和验证；\n",
    " \n",
    " - 定义数据集的路径，并创建了一个函数来加载和应用数据增强操作（如随机裁剪、随机水平翻转等），应用于训练集以提高模型泛化能力，验证集进行简单的解码、调整大小和归一化操作；\n",
    " \n",
    " - 将图像数据集分批处理，以便于训练过程中的批处理，打印出训练集和验证集的批次数（即数据集大小除以批量大小），并展示验证集中第一个批次图像的张量形状和标签；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b38a27",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "batch_size = 64                             # 批量大小\n",
    "image_size = 224                            # 训练图像空间大小\n",
    "num_epochs = 25                             # 训练周期数\n",
    "lr = 0.001                                  # 学习率\n",
    "momentum = 0.6                              # 动量\n",
    "workers = 4                                 # 并行线程个数\n",
    "import mindspore\n",
    "mindspore.set_context(device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5f10b-682e-4391-87c4-9a4294678b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "\n",
    "# 数据集目录路径\n",
    "data_path_train = \"pifudata_Maker/images/train\"\n",
    "data_path_val = \"pifudata_Maker/images/val\"\n",
    "\n",
    "# 创建训练数据集\n",
    "\n",
    "def create_dataset_canidae(dataset_path, usage):\n",
    "    \"\"\"数据加载\"\"\"\n",
    "    data_set = ds.ImageFolderDataset(dataset_path,\n",
    "                                     num_parallel_workers=workers,\n",
    "                                     shuffle=True,)\n",
    "    # 数据增强操作\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "    scale = 32\n",
    "    if usage == \"train\":\n",
    "        # Define map operations for training dataset\n",
    "        trans = [\n",
    "            vision.RandomCropDecodeResize(size=image_size, scale=(0.08, 1.0), ratio=(0.75, 1.333)),\n",
    "            vision.RandomHorizontalFlip(prob=0.5),\n",
    "            vision.Normalize(mean=mean, std=std),\n",
    "            vision.HWC2CHW()\n",
    "        ]\n",
    "    else:\n",
    "        # Define map operations for inference dataset\n",
    "        trans = [\n",
    "            vision.Decode(),\n",
    "            vision.Resize(image_size + scale),\n",
    "            vision.CenterCrop(image_size),\n",
    "            vision.Normalize(mean=mean, std=std),\n",
    "            vision.HWC2CHW()\n",
    "        ]\n",
    "\n",
    "    # 数据映射操作\n",
    "    data_set = data_set.map(\n",
    "        operations=trans,\n",
    "        input_columns='image',\n",
    "        num_parallel_workers=workers)\n",
    "    # 批量操作\n",
    "    data_set = data_set.batch(batch_size)\n",
    "    return data_set\n",
    "\n",
    "\n",
    "dataset_train = create_dataset_canidae(data_path_train, \"train\")\n",
    "step_size_train = dataset_train.get_dataset_size()\n",
    "dataset_val = create_dataset_canidae(data_path_val, \"val\")\n",
    "step_size_val = dataset_val.get_dataset_size()\n",
    "print(step_size_train)\n",
    "print(step_size_val)\n",
    "data = next(dataset_val.create_dict_iterator())\n",
    "images = data[\"image\"]\n",
    "labels = data[\"label\"]\n",
    "# print(data[\"image\"][0])\n",
    "print(\"Tensor of image\", images.shape)\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51b08a",
   "metadata": {},
   "source": [
    "### 2.5 数据集可视化\n",
    "\n",
    "为了更便于理解和调试代码，我们使用matplotlib库和numpy库来可视化数据集中的前四个图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808dc94",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# class_name对应label，按文件夹字符串从小到大的顺序标记label\n",
    "class_name = {\n",
    "    0: \"basal_cell_carcinoma\",\n",
    "    1: \"melanoma\",\n",
    "    2: \"nevus\",\n",
    "    3: \"pigmented_benign_keratosis\",\n",
    "}\n",
    "\n",
    "# print(images[0])\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(4):\n",
    "    # 获取图像及其对应的label\n",
    "    # print(images[i])\n",
    "    data_image = images[i].asnumpy()\n",
    "    data_label = labels[i]\n",
    "    # 处理图像供展示使用\n",
    "    data_image = np.transpose(data_image, (1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    data_image = std * data_image + mean\n",
    "    data_image = np.clip(data_image, 0, 1)\n",
    "    # 显示图像\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(data_image)\n",
    "    plt.title(class_name[int(labels[i].asnumpy())])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ef7e7",
   "metadata": {},
   "source": [
    "## 3 模型训练\n",
    "### 3.1 网络搭建\n",
    "\n",
    "在MindSpore中构建和配置深度残差网络，用于图像识别等任务，通过代码定义一个基于MindSpore框架的ResNet（残差网络）模型，包括基本的残差块（ResidualBlockBase和ResidualBlock）和完整的ResNet类；\n",
    "\n",
    "提供_resnet和resnet50函数来实例化ResNet模型，加载预训练权重；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330470a-5782-46ff-abe8-1f4661e1f5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Type, Union, List, Optional\n",
    "from mindspore import nn, train\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "\n",
    "weight_init = Normal(mean=0, sigma=0.02)\n",
    "gamma_init = Normal(mean=1, sigma=0.02)\n",
    "class ResidualBlockBase(nn.Cell):\n",
    "    expansion: int = 1  # 最后一个卷积核数量与第一个卷积核数量相等\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlockBase, self).__init__()\n",
    "        if not norm:\n",
    "            self.norm = nn.BatchNorm2d(out_channel)\n",
    "        else:\n",
    "            self.norm = norm\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=3, stride=stride,\n",
    "                               weight_init=weight_init)\n",
    "        self.conv2 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=3, weight_init=weight_init)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualBlockBase construct.\"\"\"\n",
    "        identity = x  # shortcuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：3*3卷积层\n",
    "        out = self.norm(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "        out = self.norm(out)\n",
    "\n",
    "        if self.down_sample is not None:\n",
    "            identity = self.down_sample(x)\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4  # 最后一个卷积核的数量是第一个卷积核数量的4倍\n",
    "\n",
    "    def __init__(self, in_channel: int, out_channel: int,\n",
    "                 stride: int = 1, down_sample: Optional[nn.Cell] = None) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel,\n",
    "                               kernel_size=1, weight_init=weight_init)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel,\n",
    "                               kernel_size=3, stride=stride,\n",
    "                               weight_init=weight_init)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(out_channel, out_channel * self.expansion,\n",
    "                               kernel_size=1, weight_init=weight_init)\n",
    "        self.norm3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "\n",
    "        identity = x  # shortscuts分支\n",
    "\n",
    "        out = self.conv1(x)  # 主分支第一层：1*1卷积层\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # 主分支第二层：3*3卷积层\n",
    "        out = self.norm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)  # 主分支第三层：1*1卷积层\n",
    "        out = self.norm3(out)\n",
    "\n",
    "        if self.down_sample is not None:\n",
    "            identity = self.down_sample(x)\n",
    "\n",
    "        out += identity  # 输出为主分支与shortcuts之和\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "def make_layer(last_out_channel, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "               channel: int, block_nums: int, stride: int = 1):\n",
    "    down_sample = None  # shortcuts分支\n",
    "\n",
    "\n",
    "    if stride != 1 or last_out_channel != channel * block.expansion:\n",
    "\n",
    "        down_sample = nn.SequentialCell([\n",
    "            nn.Conv2d(last_out_channel, channel * block.expansion,\n",
    "                      kernel_size=1, stride=stride, weight_init=weight_init),\n",
    "            nn.BatchNorm2d(channel * block.expansion, gamma_init=gamma_init)\n",
    "        ])\n",
    "\n",
    "    layers = []\n",
    "    layers.append(block(last_out_channel, channel, stride=stride, down_sample=down_sample))\n",
    "\n",
    "    in_channel = channel * block.expansion\n",
    "    # 堆叠残差网络\n",
    "    for _ in range(1, block_nums):\n",
    "\n",
    "        layers.append(block(in_channel, channel))\n",
    "\n",
    "    return nn.SequentialCell(layers)\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    def __init__(self, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "                 layer_nums: List[int], num_classes: int, input_channel: int) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # 第一个卷积层，输入channel为3（彩色图像），输出channel为64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, weight_init=weight_init)\n",
    "        self.norm = nn.BatchNorm2d(64)\n",
    "        # 最大池化层，缩小图片的尺寸\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "        # 各个残差网络结构块定义，\n",
    "        self.layer1 = make_layer(64, block, 64, layer_nums[0])\n",
    "        self.layer2 = make_layer(64 * block.expansion, block, 128, layer_nums[1], stride=2)\n",
    "        self.layer3 = make_layer(128 * block.expansion, block, 256, layer_nums[2], stride=2)\n",
    "        self.layer4 = make_layer(256 * block.expansion, block, 512, layer_nums[3], stride=2)\n",
    "        # 平均池化层\n",
    "        self.avg_pool = nn.AvgPool2d()\n",
    "        # flattern层\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 全连接层\n",
    "        self.fc = nn.Dense(in_channels=input_channel, out_channels=num_classes)\n",
    "\n",
    "    def construct(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(model_url: str, block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "            layers: List[int], num_classes: int, pretrained: bool, pretrianed_ckpt: str,\n",
    "            input_channel: int):\n",
    "    model = ResNet(block, layers, num_classes, input_channel)\n",
    "\n",
    "    if pretrained:\n",
    "        # 加载预训练模型\n",
    "        download(url=model_url, path=pretrianed_ckpt, replace=True)\n",
    "        param_dict = load_checkpoint(pretrianed_ckpt)\n",
    "        load_param_into_net(model, param_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(num_classes: int = 1000, pretrained: bool = False):\n",
    "    \"ResNet50模型\"\n",
    "    resnet50_url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/application/resnet50_224_new.ckpt\"\n",
    "    resnet50_ckpt = \"./pretrainmodel/resnet50_224_new.ckpt\"\n",
    "    return _resnet(resnet50_url, ResidualBlock, [3, 4, 6, 3], num_classes,\n",
    "                   pretrained, resnet50_ckpt, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed044fe",
   "metadata": {},
   "source": [
    "### 3.2 模型训练\n",
    "\n",
    "使用MindSpore框架在NPU上训练一个自定义的ResNet50模型，该模型被修改为用于一个4类的分类任务；\n",
    "\n",
    "定义优化器、损失函数和评估指标，实例化训练模型，选择最佳准确率以及最佳模型检查点路径保存；\n",
    "\n",
    "    --------------------\n",
    "    Epoch: [ 23/ 25], Average Train Loss: [0.418], Accuracy: [0.734]\n",
    "    epoch time: 4133.578 ms, per step time: 158.984 ms\n",
    "    --------------------\n",
    "    Epoch: [ 24/ 25], Average Train Loss: [0.448], Accuracy: [0.719]\n",
    "    epoch time: 3491.099 ms, per step time: 134.273 ms\n",
    "    --------------------\n",
    "    Epoch: [ 25/ 25], Average Train Loss: [0.390], Accuracy: [0.719]\n",
    "    epoch time: 3515.689 ms, per step time: 135.219 ms\n",
    "    ================================================================================\n",
    "    End of validation the best Accuracy is:  0.734, save the best ckpt file in ./BestCheckpoint/resnet50-best.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab705741-6fa3-4b23-aeb0-1a1eea32a723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 代码中首先导入了必要的MindSpore模块和函数，并设置了运行环境。\n",
    "import mindspore\n",
    "from mindspore import nn, train\n",
    "from mindspore.nn import Loss, Accuracy\n",
    "!pip install download\n",
    "import mindspore as ms\n",
    "from download import download\n",
    "\n",
    "network = resnet50(pretrained=True)\n",
    "\n",
    "# 通过替换ResNet50的原始全连接层和平均池化层来适配新的任务\n",
    "# 全连接层输入层的大小\n",
    "in_channels = network.fc.in_channels\n",
    "# 输出通道数大小为皮肤肿瘤分类数4\n",
    "head = nn.Dense(in_channels, 4)\n",
    "# 重置全连接层\n",
    "network.fc = head\n",
    "\n",
    "# 平均池化层kernel size为7\n",
    "avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "# 重置平均池化层\n",
    "network.avg_pool = avg_pool\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "opt = nn.Momentum(params=network.trainable_params(), learning_rate=lr, momentum=momentum)\n",
    "loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "\n",
    "# 实例化模型\n",
    "model = train.Model(network, loss_fn, opt, metrics={\"Accuracy\": Accuracy()})\n",
    "\n",
    "def forward_fn(inputs, targets):\n",
    "\n",
    "    logits = network(inputs)\n",
    "    loss = loss_fn(logits, targets)\n",
    "\n",
    "    return loss\n",
    "\n",
    "grad_fn = mindspore.ops.value_and_grad(forward_fn, None, opt.parameters)\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "\n",
    "    loss, grads = grad_fn(inputs, targets)\n",
    "    opt(grads)\n",
    "\n",
    "    return loss\n",
    "    \n",
    "# 创建迭代器\n",
    "data_loader_train = dataset_train.create_tuple_iterator(num_epochs=num_epochs)\n",
    "# 最佳模型保存路径\n",
    "best_ckpt_dir = \"./BestCheckpoint\"\n",
    "best_ckpt_path = \"./BestCheckpoint/resnet50-best.ckpt\"\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 开始循环训练\n",
    "print(\"Start Training Loop ...\")\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# 训练循环中，数据通过迭代器被加载，模型在每个epoch中更新权重，并计算训练损失。\n",
    "# 在每个epoch结束时，模型在验证集上评估准确率，并保存具有最高准确率的模型检查点。\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    network.set_train()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # 为每轮训练读入数据\n",
    "    for i, (images, labels) in enumerate(data_loader_train):\n",
    "        labels = labels.astype(ms.int32)\n",
    "        loss = train_step(images, labels)\n",
    "        losses.append(loss)\n",
    "\n",
    "    # 每个epoch结束后，验证准确率\n",
    "\n",
    "    acc = model.eval(dataset_val)['Accuracy']\n",
    "\n",
    "    epoch_end = time.time()\n",
    "    epoch_seconds = (epoch_end - epoch_start) * 1000\n",
    "    step_seconds = epoch_seconds/step_size_train\n",
    "\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Epoch: [%3d/%3d], Average Train Loss: [%5.3f], Accuracy: [%5.3f]\" % (\n",
    "        epoch+1, num_epochs, sum(losses)/len(losses), acc\n",
    "    ))\n",
    "    print(\"epoch time: %5.3f ms, per step time: %5.3f ms\" % (\n",
    "        epoch_seconds, step_seconds\n",
    "    ))\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        if not os.path.exists(best_ckpt_dir):\n",
    "            os.mkdir(best_ckpt_dir)\n",
    "        ms.save_checkpoint(network, best_ckpt_path)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"End of validation the best Accuracy is: {best_acc: 5.3f}, \"\n",
    "      f\"save the best ckpt file in {best_ckpt_path}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86921f",
   "metadata": {},
   "source": [
    "### 3.3 模型评估\n",
    "\n",
    " 从验证数据集中提取了一批次的数据，使用模型进行预测，并根据预测结果将图像及其预测标签以蓝色（正确）或红色（错误）显示。\n",
    " \n",
    " 使用matplotlib库绘制了一个包含四个子图的图像，每个子图展示了一张图像及其预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507ca27",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mindspore as ms\n",
    "\n",
    "def visualize_model(best_ckpt_path, val_ds):\n",
    "    net = resnet50()\n",
    "    # 全连接层输入层的大小\n",
    "    in_channels = net.fc.in_channels\n",
    "    # 输出通道数大小为分类数4\n",
    "    head = nn.Dense(in_channels, 4)\n",
    "    # 重置全连接层\n",
    "    net.fc = head\n",
    "    # 平均池化层kernel size为7\n",
    "    avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "    # 重置平均池化层\n",
    "    net.avg_pool = avg_pool\n",
    "    # 加载模型参数\n",
    "    param_dict = ms.load_checkpoint(best_ckpt_path)\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "    model = train.Model(net)\n",
    "    # 加载验证集的数据进行验证\n",
    "    data = next(val_ds.create_dict_iterator())\n",
    "    images = data[\"image\"].asnumpy()\n",
    "    # print(type(images))\n",
    "    # print(images.shape)\n",
    "    #print(images)\n",
    "    labels = data[\"label\"].asnumpy()\n",
    "    #print(labels)\n",
    "    class_name = {\n",
    "        0: \"basal_cell_carcinoma\",\n",
    "        1: \"melanoma\",\n",
    "        2: \"nevus\",\n",
    "        3: \"pigmented_benign_keratosis\"\n",
    "    }\n",
    "\n",
    "    # 预测图像类别\n",
    "    data_pre=ms.Tensor(data[\"image\"])\n",
    "    # print(data_pre.shape)\n",
    "    # print(type(data_pre))\n",
    "    output = model.predict(data_pre)\n",
    "\n",
    "    # print(output)\n",
    "    pred = np.argmax(output.asnumpy(), axis=1)\n",
    "\n",
    "    # 显示图像及图像的预测值\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        # 若预测正确，显示为蓝色；若预测错误，显示为红色\n",
    "        color = 'blue' if pred[i] == labels[i] else 'red'\n",
    "        plt.title('predict:{}'.format(class_name[pred[i]]), color=color,fontsize=7)\n",
    "        picture_show = np.transpose(images[i], (1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        picture_show = std * picture_show + mean\n",
    "        picture_show = np.clip(picture_show, 0, 1)\n",
    "        plt.imshow(picture_show)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "visualize_model('BestCheckpoint/resnet50-best.ckpt', dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f9522-a582-4bcf-919d-a4f58abe8e39",
   "metadata": {},
   "source": [
    "## 4 推理使用 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e357d-878b-470a-982d-5b0419c526c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mindspore as ms\n",
    "from mindspore import nn\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "import mindspore.numpy as mnp\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # 使用PIL加载图像\n",
    "    from PIL import Image\n",
    "    image = Image.open(image_path)\n",
    "    # 转换图像为RGB模式\n",
    "    image = image.convert('RGB')\n",
    "    # 调整图像大小以匹配模型输入\n",
    "    image = image.resize((224, 224))  # 假设模型输入大小为224x224\n",
    "    # 将图像转换为numpy数组\n",
    "    image_array = np.array(image)\n",
    "    # 归一化图像数组\n",
    "    image_array = image_array / 255.0\n",
    "    image_array = np.transpose(image_array, (2, 0, 1))\n",
    "    # 扩展维度以匹配模型输入，例如 (1, 3, 224, 224)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    return image_array.astype(np.float32)  # 确保数据类型为float32\n",
    "\n",
    "def visualize_prediction(image_path, best_ckpt_path):\n",
    "    net = resnet50()\n",
    "    # 全连接层输入层的大小\n",
    "    in_channels = net.fc.in_channels\n",
    "    # 输出通道数大小为分类数4\n",
    "    head = nn.Dense(in_channels, 4)\n",
    "    # 重置全连接层\n",
    "    net.fc = head\n",
    "    # 平均池化层kernel size为7\n",
    "    avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "    # 重置平均池化层\n",
    "    net.avg_pool = avg_pool\n",
    "    # 加载模型参数\n",
    "    param_dict = ms.load_checkpoint(best_ckpt_path)\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "    model = train.Model(net)\n",
    "    # 预处理图像\n",
    "    image = preprocess_image(image_path)\n",
    "    data_pre = ms.Tensor(image)\n",
    "    print(data_pre.shape)\n",
    "    print(type(data_pre)) \n",
    "    class_name = {\n",
    "        0: \"basal_cell_carcinoma\",\n",
    "        1: \"melanoma\",\n",
    "        2: \"nevus\",\n",
    "        3: \"pigmented_benign_keratosis\"\n",
    "    }\n",
    "    output = model.predict(data_pre)\n",
    "    print(output)\n",
    "    pred = np.argmax(output.asnumpy(), axis=1)\n",
    "    print(pred)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title('predict:{}'.format(class_name[pred[0]]))\n",
    "    picture_show = image[0]  # 已经是归一化后的图像\n",
    "    picture_show = np.transpose(picture_show, (1, 2, 0))  # 转换为(224, 224, 3)\n",
    "    plt.imshow(picture_show)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数，传入图片路径和模型检查点路径\n",
    "visualize_prediction('pifudata_Maker/images/val/2/ISIC_0000005.jpg', 'BestCheckpoint/resnet50-best.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
