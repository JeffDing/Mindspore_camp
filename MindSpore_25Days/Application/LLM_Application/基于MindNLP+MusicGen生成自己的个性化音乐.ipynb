{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70300319-d206-43ce-b3bf-3da6b079f20f",
   "metadata": {
    "id": "70300319-d206-43ce-b3bf-3da6b079f20f"
   },
   "source": [
    "## 基于MindNLP+MusicGen生成自己的个性化音乐\n",
    "\n",
    "MusicGen是来自Meta AI的Jade Copet等人提出的基于单个语言模型（LM）的音乐生成模型，能够根据文本描述或音频提示生成高质量的音乐样本，相关研究成果参考论文《[Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)》。\n",
    "\n",
    "MusicGen模型基于Transformer结构，可以分解为三个不同的阶段:\n",
    "1. 用户输入的文本描述作为输入传递给一个固定的文本编码器模型，以获得一系列隐形状态表示。\n",
    "2. 训练MusicGen解码器来预测离散的隐形状态音频token。\n",
    "3. 对这些音频token使用音频压缩模型（如EnCodec）进行解码，以恢复音频波形。\n",
    "\n",
    "MusicGen直接使用谷歌的[t5-base](https://huggingface.co/t5-base)及其权重作为文本编码器模型，并使用[EnCodec 32kHz](https://huggingface.co/facebook/encodec_32khz)及其权重作为音频压缩模型。MusicGen解码器是一个语言模型架构，针对音乐生成任务从零开始进行训练。\n",
    "\n",
    "\n",
    "MusicGen 模型的新颖之处在于音频代码的预测方式。传统上，每个码本都必须由一个单独的模型（即分层）或通过不断优化 Transformer 模型的输出（即上采样）进行预测。与传统方法不同，MusicGen采用单个stage的Transformer LM结合高效的token交织模式，取消了多层级的多个模型结构，例如分层或上采样，这使得MusicGen能够生成单声道和立体声的高质量音乐样本，同时提供更好的生成输出控制。MusicGen不仅能够生成符合文本描述的音乐，还能够通过旋律条件控制生成的音调结构。\n",
    "\n",
    "![dealy_pattern](pic/delay_pattern.png)\n",
    "\n",
    "\n",
    "**Figure 1:** MusicGen使用的码本延迟模式，来源于 [MusicGen paper](https://arxiv.org/abs/2306.05284).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee39cc-654b-4f0e-b601-013e484c16f0",
   "metadata": {
    "id": "77ee39cc-654b-4f0e-b601-013e484c16f0"
   },
   "source": [
    "## 下载模型\n",
    "\n",
    "MusicGen提供了small、medium和big三种规格的[预训练权重文件](https://huggingface.co/models?search=facebook/musicgen-)，本次指南默认使用small规格的权重，生成的音频质量较低，但是生成的速度是最快的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4797a5025ddcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 实验环境已经预装了mindspore==2.2.14，如需更换mindspore版本，可更改下面mindspore的版本号\n",
    "!pip uninstall mindspore -y\n",
    "!pip install -i https://pypi.mirrors.ustc.edu.cn/simple mindspore==2.2.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19d164-c09a-4952-b599-3e36a0f87b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# 该案例在 mindnlp 0.3.1 版本完成适配，如果发现案例跑不通，可以指定mindnlp版本，执行`!pip install mindnlp==0.3.1 jieba soundfile librosa`\n",
    "!pip install -i https://pypi.mirrors.ustc.edu.cn/simple mindnlp jieba soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e1fceebec29c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看当前 mindspore 版本\n",
    "!pip show mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d87424-9f38-4658-ba47-2a465d52ad77",
   "metadata": {
    "id": "b0d87424-9f38-4658-ba47-2a465d52ad77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindnlp.transformers import MusicgenForConditionalGeneration\n",
    "\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1166e-1335-4555-9ec4-223d1fbcb547",
   "metadata": {
    "id": "f6e1166e-1335-4555-9ec4-223d1fbcb547"
   },
   "source": [
    "## 生成音乐\n",
    "\n",
    "MusicGen支持两种生成模式：贪心（greedy）和采样（sampling）。在实际执行过程中，采样模式得到的结果要显著优于贪心模式。因此我们默认启用采样模式，并且可以在调用`MusicgenForConditionalGeneration.generate`时设置`do_sample=True`来显式指定使用采样模式。\n",
    "\n",
    "### 无提示生成\n",
    "\n",
    "我们可以通过方法 `MusicgenForConditionalGeneration.get_unconditional_inputs` 获得网络的随机输入，然后使用 `.generate` 方法进行自回归生成，指定 `do_sample=True` 来启用采样模式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7708e8-e4f1-4ab8-b04a-19395d78dea2",
   "metadata": {
    "id": "fb7708e8-e4f1-4ab8-b04a-19395d78dea2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "unconditional_inputs = model.get_unconditional_inputs(num_samples=1)\n",
    "\n",
    "audio_values = model.generate(**unconditional_inputs, do_sample=True, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb74df-c194-4d2e-930a-12473b08a919",
   "metadata": {
    "id": "94cb74df-c194-4d2e-930a-12473b08a919"
   },
   "source": [
    "音频输出是格式是: a Torch tensor of shape `(batch_size, num_channels, sequence_length)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de58334-40f7-4924-addb-2d6ff34c0590",
   "metadata": {
    "id": "6de58334-40f7-4924-addb-2d6ff34c0590"
   },
   "source": [
    "使用第三方库`scipy`将输出的音频保存为`musicgen_out.wav` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04291f52-0a75-4ddb-9eff-e853d0f17288",
   "metadata": {
    "id": "04291f52-0a75-4ddb-9eff-e853d0f17288",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "scipy.io.wavfile.write(\"musicgen_out.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d212314085564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "# 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ff5b2-c170-4079-93a4-a02acbdaeb39",
   "metadata": {
    "id": "e52ff5b2-c170-4079-93a4-a02acbdaeb39"
   },
   "source": [
    "参数 `max_new_tokens` 指定要生成 `token` 数。根据经验，可以使用 `EnCodec` 模型的帧速率计算出生成的音频样本的长度（以秒为单位）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ad107-e19b-47f3-9cf1-5102ab4ae74a",
   "metadata": {
    "id": "d75ad107-e19b-47f3-9cf1-5102ab4ae74a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_length_in_s = 256 / model.config.audio_encoder.frame_rate\n",
    "\n",
    "audio_length_in_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e999b-2595-4090-8e1a-acfaa42d2581",
   "metadata": {
    "id": "9a0e999b-2595-4090-8e1a-acfaa42d2581"
   },
   "source": [
    "### 文本提示生成\n",
    "\n",
    "首先基于文本提示，通过`AutoProcessor`对输入进行预处理。然后将预处理后的输入传递给 `.generate` 方法以生成文本条件音频样本。同样，我们通过设置“do_sample=True”来启用采样模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741428a-7368-4b01-88d3-8608786252f5",
   "metadata": {},
   "source": [
    "其中，`guidance_scale` 用于无分类器指导（CFG），设置条件对数之间的权重（从文本提示中预测）和无条件对数（从无条件或空文本中预测）。`guidance_scale`越高表示生成的模型与输入的文本更加紧密。通过设置`guidance_scale > 1`来启用 CFG。为获得最佳效果，使用`guidance_scale=3`（默认值）生成文本提示音频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba4154-13f6-403a-958b-101d6eacfb6e",
   "metadata": {
    "id": "5fba4154-13f6-403a-958b-101d6eacfb6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from mindnlp.transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[\"80s pop track with bassy drums and synth\", \"90s rock song with loud guitars and heavy drums\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"ms\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161179f5-f2ea-498f-8b24-020791fcb483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\"musicgen_out_text.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8574181bee9a8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "# 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391b2a1-6376-4b69-b562-4388b731cf60",
   "metadata": {
    "id": "d391b2a1-6376-4b69-b562-4388b731cf60"
   },
   "source": [
    "### 音频提示生成\n",
    "\n",
    "`AutoProcessor`同样可以对用于音频预测的音频提示进行预处理。在以下示例中，我们首先加载音频文件，然后进行预处理，并将输入给到网络模型来进行音频生成。最后，我们将生成出来的音频文件保存为` musicgen_out_audio.wav `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5c28a-f6c1-4ac8-ae08-6776a2b2c5b8",
   "metadata": {
    "id": "56a5c28a-f6c1-4ac8-ae08-6776a2b2c5b8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from datasets import load_dataset\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "dataset = load_dataset(\"sanchit-gandhi/gtzan\", split=\"train\", streaming=True)\n",
    "sample = next(iter(dataset))[\"audio\"]\n",
    "\n",
    "# take the first half of the audio sample\n",
    "sample[\"array\"] = sample[\"array\"][: len(sample[\"array\"]) // 2]\n",
    "\n",
    "inputs = processor(\n",
    "    audio=sample[\"array\"],\n",
    "    sampling_rate=sample[\"sampling_rate\"],\n",
    "    text=[\"80s blues track with groovy saxophone\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"ms\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682165f-8715-4209-877d-29d0e1e8c85c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\"musicgen_out_audio.wav\", rate=sampling_rate, data=audio_values[0, 0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283b99a48d83447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "# 要收听生成的音频样本，可以使用 Audio 在 notebook 进行播放\n",
    "Audio(audio_values[0].asnumpy(), rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b33d3-02d6-416f-8263-0d9bcc55ea60",
   "metadata": {},
   "source": [
    "为了演示批量音频提示生成，我们将按两个不同的比例对样本音频进行切片，以提供两个不同长度的音频样本。由于输入音频提示的长度各不相同，因此在传递到模型之前，它们将被填充到批处理中最长的音频样本的长度。\n",
    "\n",
    "要恢复最终音频样本，可以对生成的audio_values进行后处理，以再次使用处理器类删除填充："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7de2ca-1d45-47ad-bbb5-645c1f4227fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = next(iter(dataset))[\"audio\"]\n",
    "\n",
    "# take the first quater of the audio sample\n",
    "sample_1 = sample[\"array\"][: len(sample[\"array\"]) // 4]\n",
    "\n",
    "# take the first half of the audio sample\n",
    "sample_2 = sample[\"array\"][: len(sample[\"array\"]) // 2]\n",
    "\n",
    "inputs = processor(\n",
    "    audio=[sample_1, sample_2],\n",
    "    sampling_rate=sample[\"sampling_rate\"],\n",
    "    text=[\"80s blues track with groovy saxophone\", \"90s rock song with loud guitars and heavy drums\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"ms\",\n",
    ")\n",
    "\n",
    "audio_values = model.generate(**inputs, do_sample=True, guidance_scale=3, max_new_tokens=256)\n",
    "\n",
    "# post-process to remove padding from the batched audio\n",
    "audio_values = processor.batch_decode(audio_values, padding_mask=inputs.padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7005c-9d1b-4294-951f-c29b1d23fd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Audio(audio_values[0], rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3c009-55aa-4e0b-abcf-f51e188f01d8",
   "metadata": {},
   "source": [
    "# 生成配置\n",
    "控制生成过程的默认参数（例如采样、指导比例和生成的令牌数量）可以在模型的生成配置中找到，并根据需要进行更新。首先，我们检查默认的生成配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9d4ac-b265-488b-859d-e88deff4a71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb391c8f-eef8-4e3b-9132-021c19505126",
   "metadata": {},
   "source": [
    "我们看到模型默认使用采样模式 （do_sample=True），指导刻度为 3，最大生成长度为 1500（相当于 30 秒的音频）。你可以更新以下任一属性以更改默认生成参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc4247-de47-4409-8ca7-abf93045685c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# increase the guidance scale to 4.0\n",
    "model.generation_config.guidance_scale = 4.0\n",
    "\n",
    "# set the max new tokens to 256\n",
    "model.generation_config.max_new_tokens = 256\n",
    "\n",
    "# set the softmax sampling temperature to 1.5\n",
    "model.generation_config.temperature = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea627e-430a-4db7-9733-67a3e2614905",
   "metadata": {},
   "source": [
    "现在重新运行生成将使用生成配置中新定义的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098de13-83b3-45bd-a78f-8c2b6acc692b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_values = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc934c50-f2b8-48a1-9055-e2a1e422907a",
   "metadata": {},
   "source": [
    "请注意，传递给 generate 方法的任何参数都将取代生成配置中的参数，因此在调用 generate 中设置 do_sample=False 将取代生成配置中 model.generation_config.do_sample 的设置。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Conda-python3",
   "language": "python",
   "name": "conda-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
