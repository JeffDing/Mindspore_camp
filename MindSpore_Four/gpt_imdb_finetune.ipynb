{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: mindnlp==0.4.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: mindspore>=2.2.14 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (2.3.1)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (4.67.0)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (2.32.3)\n",
      "Requirement already satisfied: datasets in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (3.1.0)\n",
      "Requirement already satisfied: evaluate in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.4.3)\n",
      "Requirement already satisfied: tokenizers==0.19.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.4.5)\n",
      "Requirement already satisfied: sentencepiece in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.1.99)\n",
      "Requirement already satisfied: regex in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (2023.10.3)\n",
      "Requirement already satisfied: addict in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (2.4.0)\n",
      "Requirement already satisfied: ml-dtypes in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.2.0)\n",
      "Requirement already satisfied: pyctcdecode in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.5.0)\n",
      "Requirement already satisfied: jieba in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (0.42.1)\n",
      "Requirement already satisfied: pytest==7.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (7.2.0)\n",
      "Requirement already satisfied: pillow>=10.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.0) (11.0.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (23.1.0)\n",
      "Requirement already satisfied: iniconfig in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (1.1.3)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.0) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tokenizers==0.19.1->mindnlp==0.4.0) (0.26.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (3.20.3)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (1.11.3)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (5.9.5)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.0) (1.6.3)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->mindnlp==0.4.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (3.10.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.0) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.0) (2023.7.22)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pyctcdecode->mindnlp==0.4.0) (2.5.0)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pyctcdecode->mindnlp==0.4.0) (6.118.7)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore>=2.2.14->mindnlp==0.4.0) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore>=2.2.14->mindnlp==0.4.0) (0.41.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.4.0) (4.8.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from hypothesis<7,>=6.14->pyctcdecode->mindnlp==0.4.0) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.4.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.4.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.4.0) (2023.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->mindnlp==0.4.0) (0.2.0)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping soundfile as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: download in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.3.5)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (4.67.0)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2023.7.22)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: jieba in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.42.1)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting mindspore==2.3.1\n",
      "  Using cached https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.3.1/MindSpore/unified/aarch64/mindspore-2.3.1-cp39-cp39-linux_aarch64.whl (328.8 MB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (3.20.3)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (2.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (11.0.0)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (1.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (23.2)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (5.9.5)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.3.1) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.3.1) (0.41.3)\n",
      "\u001b[33mDEPRECATION: moxing-framework 2.1.16.2ae09d45 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of moxing-framework or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#安装mindnlp 0.4.0套件\n",
    "!pip install mindnlp==0.4.0\n",
    "!pip uninstall soundfile -y\n",
    "!pip install download\n",
    "!pip install jieba\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.3.1/MindSpore/unified/aarch64/mindspore-2.3.1-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.311 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import mindspore\n",
    "from mindspore.dataset import text, GeneratorDataset, transforms\n",
    "from mindspore import nn\n",
    "\n",
    "from mindnlp.dataset import load_dataset\n",
    "\n",
    "from mindnlp.engine import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imdb_ds = load_dataset('imdb', split=['train', 'test'])\n",
    "imdb_train = imdb_ds['train']\n",
    "imdb_test = imdb_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_dataset(dataset, tokenizer, max_seq_len=512, batch_size=4, shuffle=False):\n",
    "    is_ascend = mindspore.get_context('device_target') == 'Ascend'\n",
    "    def tokenize(text):\n",
    "        if is_ascend:\n",
    "            tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=max_seq_len)\n",
    "        else:\n",
    "            tokenized = tokenizer(text, truncation=True, max_length=max_seq_len)\n",
    "        return tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    # map dataset\n",
    "    dataset = dataset.map(operations=[tokenize], input_columns=\"text\", output_columns=['input_ids', 'attention_mask'])\n",
    "    dataset = dataset.map(operations=transforms.TypeCast(mindspore.int32), input_columns=\"label\", output_columns=\"labels\")\n",
    "    # batch dataset\n",
    "    if is_ascend:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    else:\n",
    "        dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),\n",
    "                                                             'attention_mask': (None, 0)})\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/tokenization_utils_base.py:1526: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted, and will be then set to `False` by default. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.transformers import OpenAIGPTTokenizer\n",
    "# tokenizer\n",
    "gpt_tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "\n",
    "# add sepcial token: <PAD>\n",
    "special_tokens_dict = {\n",
    "    \"bos_token\": \"<bos>\",\n",
    "    \"eos_token\": \"<eos>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "}\n",
    "num_added_toks = gpt_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这行代码是为了方便体验流程，把原本数据集的十分之一拿出来体验训练和评估,体验该完整的数据集，可以将这行代码注释掉\n",
    "imdb_train, _ = imdb_train.split([0.1, 0.9], randomize=False)\n",
    "\n",
    "# split train dataset into train and valid datasets\n",
    "imdb_train, imdb_val = imdb_train.split([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = process_dataset(imdb_train, gpt_tokenizer, shuffle=True)\n",
    "dataset_val = process_dataset(imdb_val, gpt_tokenizer)\n",
    "dataset_test = process_dataset(imdb_test, gpt_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[4, 512], dtype=Int64, value=\n",
       " [[  616,  5648,  5973 ... 40480, 40480, 40480],\n",
       "  [  249, 34531,   256 ... 40480, 40480, 40480],\n",
       "  [  481,  2502,  7322 ...  3808,   481,  1164],\n",
       "  [ 1684,   616,   504 ... 40480, 40480, 40480]]),\n",
       " Tensor(shape=[4, 512], dtype=Int64, value=\n",
       " [[1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 1, 1, 1],\n",
       "  [1, 1, 1 ... 0, 0, 0]]),\n",
       " Tensor(shape=[4], dtype=Int32, value= [0, 0, 0, 0])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset_train.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OpenAIGPTForSequenceClassification were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.transformers import OpenAIGPTForSequenceClassification\n",
    "from mindnlp import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# set bert config and define parameters for training\n",
    "model = OpenAIGPTForSequenceClassification.from_pretrained('openai-gpt', num_labels=2)\n",
    "model.config.pad_token_id = gpt_tokenizer.pad_token_id\n",
    "model.resize_token_embeddings(model.config.vocab_size + 3)\n",
    "\n",
    "from mindnlp.engine import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gpt_imdb_finetune\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=1.0,\n",
    "    learning_rate=2e-5\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注: 如果想要运行的更快一些，可以在训练时需要V100的算力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [03:11<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0024, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/188 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 2/188 [00:00<01:17,  2.40it/s]\u001b[A\n",
      "  2%|▏         | 3/188 [00:01<02:11,  1.41it/s]\u001b[A\n",
      "  2%|▏         | 4/188 [00:02<02:20,  1.31it/s]\u001b[A\n",
      "  3%|▎         | 5/188 [00:03<02:38,  1.16it/s]\u001b[A\n",
      "  3%|▎         | 6/188 [00:04<02:30,  1.21it/s]\u001b[A\n",
      "  4%|▎         | 7/188 [00:05<02:34,  1.17it/s]\u001b[A\n",
      "  4%|▍         | 8/188 [00:06<02:37,  1.15it/s]\u001b[A\n",
      "  5%|▍         | 9/188 [00:06<01:55,  1.55it/s]\u001b[A\n",
      "  5%|▌         | 10/188 [00:06<01:28,  2.02it/s]\u001b[A\n",
      "  6%|▌         | 11/188 [00:06<01:07,  2.61it/s]\u001b[A\n",
      "  6%|▋         | 12/188 [00:06<00:53,  3.29it/s]\u001b[A\n",
      "  7%|▋         | 13/188 [00:07<00:43,  3.98it/s]\u001b[A\n",
      "  7%|▋         | 14/188 [00:07<00:37,  4.67it/s]\u001b[A\n",
      "  8%|▊         | 15/188 [00:07<00:31,  5.52it/s]\u001b[A\n",
      "  9%|▊         | 16/188 [00:07<00:29,  5.77it/s]\u001b[A\n",
      "  9%|▉         | 17/188 [00:07<00:27,  6.21it/s]\u001b[A\n",
      " 10%|▉         | 18/188 [00:07<00:24,  7.00it/s]\u001b[A\n",
      " 10%|█         | 19/188 [00:07<00:23,  7.29it/s]\u001b[A\n",
      " 11%|█         | 20/188 [00:07<00:22,  7.41it/s]\u001b[A\n",
      " 11%|█         | 21/188 [00:08<00:21,  7.66it/s]\u001b[A\n",
      " 12%|█▏        | 22/188 [00:08<00:22,  7.52it/s]\u001b[A\n",
      " 12%|█▏        | 23/188 [00:08<00:21,  7.60it/s]\u001b[A\n",
      " 13%|█▎        | 25/188 [00:08<00:19,  8.47it/s]\u001b[A\n",
      " 14%|█▍        | 26/188 [00:08<00:18,  8.58it/s]\u001b[A\n",
      " 14%|█▍        | 27/188 [00:08<00:21,  7.39it/s]\u001b[A\n",
      " 15%|█▌        | 29/188 [00:09<00:19,  8.33it/s]\u001b[A\n",
      " 16%|█▌        | 30/188 [00:09<00:18,  8.34it/s]\u001b[A\n",
      " 16%|█▋        | 31/188 [00:09<00:21,  7.27it/s]\u001b[A\n",
      " 17%|█▋        | 32/188 [00:09<00:20,  7.62it/s]\u001b[A\n",
      " 18%|█▊        | 34/188 [00:09<00:19,  7.79it/s]\u001b[A\n",
      " 19%|█▊        | 35/188 [00:09<00:19,  7.86it/s]\u001b[A\n",
      " 19%|█▉        | 36/188 [00:10<00:21,  7.04it/s]\u001b[A\n",
      " 20%|█▉        | 37/188 [00:10<00:21,  7.13it/s]\u001b[A\n",
      " 20%|██        | 38/188 [00:10<00:20,  7.29it/s]\u001b[A\n",
      " 21%|██        | 39/188 [00:10<00:19,  7.60it/s]\u001b[A\n",
      " 21%|██▏       | 40/188 [00:10<00:18,  7.98it/s]\u001b[A\n",
      " 22%|██▏       | 41/188 [00:10<00:18,  7.89it/s]\u001b[A\n",
      " 22%|██▏       | 42/188 [00:10<00:18,  7.92it/s]\u001b[A\n",
      " 23%|██▎       | 43/188 [00:10<00:17,  8.41it/s]\u001b[A\n",
      " 23%|██▎       | 44/188 [00:11<00:18,  7.98it/s]\u001b[A\n",
      " 24%|██▍       | 45/188 [00:11<00:17,  8.32it/s]\u001b[A\n",
      " 24%|██▍       | 46/188 [00:11<00:16,  8.55it/s]\u001b[A\n",
      " 25%|██▌       | 47/188 [00:11<00:18,  7.81it/s]\u001b[A\n",
      " 26%|██▌       | 48/188 [00:11<00:17,  7.91it/s]\u001b[A\n",
      " 26%|██▌       | 49/188 [00:11<00:18,  7.64it/s]\u001b[A\n",
      " 27%|██▋       | 50/188 [00:11<00:18,  7.60it/s]\u001b[A\n",
      " 27%|██▋       | 51/188 [00:11<00:17,  7.77it/s]\u001b[A\n",
      " 28%|██▊       | 52/188 [00:12<00:18,  7.31it/s]\u001b[A\n",
      " 28%|██▊       | 53/188 [00:12<00:18,  7.36it/s]\u001b[A\n",
      " 29%|██▊       | 54/188 [00:12<00:18,  7.35it/s]\u001b[A\n",
      " 29%|██▉       | 55/188 [00:12<00:17,  7.55it/s]\u001b[A\n",
      " 30%|███       | 57/188 [00:12<00:16,  7.97it/s]\u001b[A\n",
      " 31%|███       | 58/188 [00:12<00:15,  8.33it/s]\u001b[A\n",
      " 31%|███▏      | 59/188 [00:12<00:15,  8.42it/s]\u001b[A\n",
      " 32%|███▏      | 60/188 [00:13<00:14,  8.54it/s]\u001b[A\n",
      " 32%|███▏      | 61/188 [00:13<00:14,  8.71it/s]\u001b[A\n",
      " 33%|███▎      | 62/188 [00:13<00:14,  8.61it/s]\u001b[A\n",
      " 34%|███▎      | 63/188 [00:13<00:15,  8.11it/s]\u001b[A\n",
      " 34%|███▍      | 64/188 [00:13<00:15,  8.25it/s]\u001b[A\n",
      " 35%|███▍      | 65/188 [00:13<00:14,  8.41it/s]\u001b[A\n",
      " 35%|███▌      | 66/188 [00:13<00:14,  8.36it/s]\u001b[A\n",
      " 36%|███▌      | 67/188 [00:13<00:17,  7.05it/s]\u001b[A\n",
      " 36%|███▌      | 68/188 [00:14<00:16,  7.13it/s]\u001b[A\n",
      " 37%|███▋      | 70/188 [00:14<00:12,  9.37it/s]\u001b[A\n",
      " 38%|███▊      | 72/188 [00:14<00:09, 11.81it/s]\u001b[A\n",
      " 39%|███▉      | 74/188 [00:14<00:08, 13.73it/s]\u001b[A\n",
      " 40%|████      | 76/188 [00:14<00:07, 15.22it/s]\u001b[A\n",
      " 41%|████▏     | 78/188 [00:14<00:06, 16.38it/s]\u001b[A\n",
      " 43%|████▎     | 80/188 [00:14<00:06, 17.10it/s]\u001b[A\n",
      " 44%|████▎     | 82/188 [00:14<00:05, 17.85it/s]\u001b[A\n",
      " 45%|████▍     | 84/188 [00:14<00:05, 18.29it/s]\u001b[A\n",
      " 46%|████▌     | 86/188 [00:15<00:05, 18.47it/s]\u001b[A\n",
      " 47%|████▋     | 88/188 [00:15<00:05, 18.65it/s]\u001b[A\n",
      " 48%|████▊     | 90/188 [00:15<00:05, 18.71it/s]\u001b[A\n",
      " 49%|████▉     | 92/188 [00:15<00:05, 18.87it/s]\u001b[A\n",
      " 50%|█████     | 94/188 [00:15<00:04, 18.89it/s]\u001b[A\n",
      " 51%|█████     | 96/188 [00:15<00:04, 18.92it/s]\u001b[A\n",
      " 52%|█████▏    | 98/188 [00:15<00:04, 19.00it/s]\u001b[A\n",
      " 53%|█████▎    | 100/188 [00:15<00:04, 19.03it/s]\u001b[A\n",
      " 54%|█████▍    | 102/188 [00:15<00:04, 18.98it/s]\u001b[A\n",
      " 55%|█████▌    | 104/188 [00:16<00:04, 18.57it/s]\u001b[A\n",
      " 56%|█████▋    | 106/188 [00:16<00:04, 18.65it/s]\u001b[A\n",
      " 57%|█████▋    | 108/188 [00:16<00:04, 18.63it/s]\u001b[A\n",
      " 59%|█████▊    | 110/188 [00:16<00:04, 18.59it/s]\u001b[A\n",
      " 60%|█████▉    | 112/188 [00:16<00:04, 18.44it/s]\u001b[A\n",
      " 61%|██████    | 114/188 [00:16<00:03, 18.61it/s]\u001b[A\n",
      " 62%|██████▏   | 116/188 [00:16<00:03, 18.65it/s]\u001b[A\n",
      " 63%|██████▎   | 118/188 [00:16<00:03, 18.41it/s]\u001b[A\n",
      " 64%|██████▍   | 120/188 [00:16<00:03, 18.10it/s]\u001b[A\n",
      " 65%|██████▍   | 122/188 [00:17<00:03, 18.30it/s]\u001b[A\n",
      " 66%|██████▌   | 124/188 [00:17<00:03, 18.31it/s]\u001b[A\n",
      " 67%|██████▋   | 126/188 [00:17<00:03, 18.40it/s]\u001b[A\n",
      " 68%|██████▊   | 128/188 [00:17<00:03, 18.64it/s]\u001b[A\n",
      " 69%|██████▉   | 130/188 [00:17<00:03, 18.66it/s]\u001b[A\n",
      " 70%|███████   | 132/188 [00:17<00:02, 18.71it/s]\u001b[A\n",
      " 71%|███████▏  | 134/188 [00:17<00:02, 18.99it/s]\u001b[A\n",
      " 72%|███████▏  | 136/188 [00:17<00:02, 18.92it/s]\u001b[A\n",
      " 73%|███████▎  | 138/188 [00:17<00:02, 19.03it/s]\u001b[A\n",
      " 74%|███████▍  | 140/188 [00:17<00:02, 19.11it/s]\u001b[A\n",
      " 76%|███████▌  | 142/188 [00:18<00:02, 19.03it/s]\u001b[A\n",
      " 77%|███████▋  | 144/188 [00:18<00:02, 19.11it/s]\u001b[A\n",
      " 78%|███████▊  | 146/188 [00:18<00:02, 19.14it/s]\u001b[A\n",
      " 79%|███████▊  | 148/188 [00:18<00:02, 19.17it/s]\u001b[A\n",
      " 80%|███████▉  | 150/188 [00:18<00:01, 19.02it/s]\u001b[A\n",
      " 81%|████████  | 152/188 [00:18<00:01, 18.70it/s]\u001b[A\n",
      " 82%|████████▏ | 154/188 [00:18<00:01, 18.03it/s]\u001b[A\n",
      " 83%|████████▎ | 156/188 [00:18<00:01, 18.30it/s]\u001b[A\n",
      " 84%|████████▍ | 158/188 [00:18<00:01, 18.11it/s]\u001b[A\n",
      " 85%|████████▌ | 160/188 [00:19<00:01, 18.19it/s]\u001b[A\n",
      " 86%|████████▌ | 162/188 [00:19<00:01, 18.14it/s]\u001b[A\n",
      " 87%|████████▋ | 164/188 [00:19<00:01, 18.24it/s]\u001b[A\n",
      " 88%|████████▊ | 166/188 [00:19<00:01, 18.43it/s]\u001b[A\n",
      " 89%|████████▉ | 168/188 [00:19<00:01, 18.75it/s]\u001b[A\n",
      " 91%|█████████ | 171/188 [00:19<00:00, 19.38it/s]\u001b[A\n",
      " 93%|█████████▎| 174/188 [00:19<00:00, 19.75it/s]\u001b[A\n",
      " 94%|█████████▍| 177/188 [00:19<00:00, 20.00it/s]\u001b[A\n",
      " 95%|█████████▌| 179/188 [00:20<00:00, 19.94it/s]\u001b[A\n",
      " 96%|█████████▋| 181/188 [00:20<00:00, 19.94it/s]\u001b[A\n",
      " 98%|█████████▊| 184/188 [00:20<00:00, 20.00it/s]\u001b[A\n",
      " 99%|█████████▉| 186/188 [00:20<00:00, 19.99it/s]\u001b[A\n",
      "100%|██████████| 188/188 [00:20<00:00, 18.53it/s]\u001b[A\n",
      "                                                 \n",
      "100%|██████████| 438/438 [03:33<00:00,  2.85it/s]\u001b[A\n",
      "                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.6351964303757995e-06, 'eval_accuracy': 1.0, 'eval_runtime': 22.1623, 'eval_samples_per_second': 8.483, 'eval_steps_per_second': 1.083, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [03:48<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 228.9073, 'train_samples_per_second': 7.654, 'train_steps_per_second': 1.913, 'train_loss': 0.0024289760959747175, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=438, training_loss=0.0024289760959747175, metrics={'train_runtime': 228.9073, 'train_samples_per_second': 7.654, 'train_steps_per_second': 1.913, 'train_loss': 0.0024289760959747175, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [12:11<00:00,  8.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.262429237365723,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_runtime': 732.4071,\n",
       " 'eval_samples_per_second': 8.534,\n",
       " 'eval_steps_per_second': 1.068,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "1325b719-fc78-46c4-8f47-9f3623e9b0f4"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54202",
   "name": "mindspore1.7.0-cuda10.1-py3.7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
